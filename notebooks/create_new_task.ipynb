{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttktjmt/mjlab/blob/main/notebooks/create_new_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO76KS1i-MwA"
      },
      "source": [
        "# **ü§ñ CartPole Tutorial with MJLab**\n",
        "\n",
        "This notebook demonstrates how to create a custom reinforcement learning task using MJLab. We'll build a CartPole environment from scratch, including:\n",
        "\n",
        "1. **Robot Definition** - Define the CartPole model in MuJoCo XML\n",
        "2. **Task Configuration** - Set up observations, actions, rewards, and terminations\n",
        "3. **Training** - Train a policy using PPO\n",
        "4. **Evaluation** - Visualize/Record the trained policy\n",
        "\n",
        "> **Note**: This tutorial is created based on the official MJLab documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ywZTgfR3C_w"
      },
      "source": [
        "## **üì¶ Setup and Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dtLMJHzy3Nee",
        "outputId": "ad5b9f13-1fcf-4519-d554-641cff4980c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mjlab\n",
            "‚úì Installation complete!\n"
          ]
        }
      ],
      "source": [
        "# Clone the mjlab repository\n",
        "!if [ ! -d \"mjlab\" ]; then git clone -q https://github.com/mujocolab/mjlab.git; fi\n",
        "%cd /content/mjlab\n",
        "\n",
        "# Install mjlab in editable mode\n",
        "!uv pip install --system -e . -q\n",
        "\n",
        "print(\"‚úì Installation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSf2943z3b0s"
      },
      "source": [
        "### **üîë WandB Setup (Optional)**\n",
        "\n",
        "Configure Weights & Biases for experiment tracking. Add your WandB API key to Colab Secrets:\n",
        "- `WANDB_API_KEY`: from [wandb.ai/authorize](https://wandb.ai/authorize)\n",
        "- `WANDB_ENTITY`: your user name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC9ywCnm3dGg",
        "outputId": "732ce18c-aea2-46b3-ee17-1190201cd8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì WandB configured successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Use this and comment out to log locally\n",
        "# os.environ['WANDB_MODE'] = 'disabled'\n",
        "\n",
        "try:\n",
        "    os.environ['WANDB_API_KEY'] = userdata.get('WANDB_API_KEY')\n",
        "    os.environ['WANDB_ENTITY'] = userdata.get('WANDB_ENTITY')\n",
        "    print(\"‚úì WandB configured successfully!\")\n",
        "except (AttributeError, KeyError):\n",
        "    print(\"‚ö† WandB secrets not found. Training will proceed without WandB logging.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mispfmy73lmq"
      },
      "source": [
        "---\n",
        "\n",
        "## **ü§ñ Step 1: Define the Robot**\n",
        "\n",
        "We'll create a simple CartPole robot with:\n",
        "- A sliding cart (1 DOF)\n",
        "- A hinged pole (1 DOF)\n",
        "- A velocity actuator to control the cart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FvJYPWD3scd"
      },
      "source": [
        "### **üìÅ Structure Directories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP-yET-R3ofN",
        "outputId": "29617d6a-3ba8-4257-86d5-8e97dac277aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Directory structure created\n"
          ]
        }
      ],
      "source": [
        "# Create the cartpole robot directory structure\n",
        "!mkdir -p /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/\n",
        "!mkdir -p /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/xmls\n",
        "\n",
        "print(\"‚úì Directory structure created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRyN1Pok3u25"
      },
      "source": [
        "### **üìù Create MuJoCo XML Model**\n",
        "\n",
        "This XML defines the CartPole physics:\n",
        "- **Ground plane** for visualization\n",
        "- **Cart body** with a sliding joint (¬±2m range)\n",
        "- **Pole body** with a hinge joint (¬±90¬∞ range)\n",
        "- **Velocity actuator** for cart control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWGyFX5V3yWc",
        "outputId": "7888a777-f0c9-4ce5-ec43-092a7139df1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/xmls/cartpole.xml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/xmls/cartpole.xml\n",
        "<mujoco model=\"cartpole\">\n",
        "  <compiler angle=\"degree\" coordinate=\"local\" inertiafromgeom=\"true\"/>\n",
        "  <worldbody>\n",
        "    <geom name=\"ground\" type=\"plane\" pos=\"0 0 0\" size=\"5 5 0.1\" rgba=\"0.8 0.9 0.8 1\"/>\n",
        "    <body name=\"cart\" pos=\"0 0 0.1\">\n",
        "      <geom type=\"box\" size=\"0.2 0.1 0.1\" rgba=\"0.2 0.2 0.8 1\" mass=\"1.0\"/>\n",
        "      <joint name=\"slide\" type=\"slide\" axis=\"1 0 0\" limited=\"true\" range=\"-2 2\"/>\n",
        "      <body name=\"pole\" pos=\"0 0 0.1\">\n",
        "        <geom type=\"capsule\" size=\"0.05 0.5\" fromto=\"0 0 0 0 0 1\" rgba=\"0.8 0.2 0.2 1\" mass=\"2.0\"/>\n",
        "        <joint name=\"hinge\" type=\"hinge\" axis=\"0 1 0\" range=\"-90 90\"/>\n",
        "      </body>\n",
        "    </body>\n",
        "  </worldbody>\n",
        "  <actuator>\n",
        "    <velocity name=\"slide_velocity\" joint=\"slide\" ctrlrange=\"-20 20\" kv=\"20\"/>\n",
        "  </actuator>\n",
        "</mujoco>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpYCG9jI31dZ"
      },
      "source": [
        "### **‚öôÔ∏è Create Robot Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDhiyDTn4AVa",
        "outputId": "64cb9a91-38c1-4aaf-a068-c9555eaed3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/cartpole_constants.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/cartpole_constants.py\n",
        "from pathlib import Path\n",
        "import mujoco\n",
        "\n",
        "from mjlab import MJLAB_SRC_PATH\n",
        "from mjlab.entity import Entity, EntityCfg, EntityArticulationInfoCfg\n",
        "from mjlab.actuator import XmlVelocityActuatorCfg\n",
        "\n",
        "CARTPOLE_XML: Path = (\n",
        "  MJLAB_SRC_PATH / \"asset_zoo\" / \"robots\" / \"cartpole\" / \"xmls\" / \"cartpole.xml\"\n",
        ")\n",
        "assert CARTPOLE_XML.exists(), f\"XML not found: {CARTPOLE_XML}\"\n",
        "\n",
        "def get_spec() -> mujoco.MjSpec:\n",
        "  return mujoco.MjSpec.from_file(str(CARTPOLE_XML))\n",
        "\n",
        "def get_cartpole_robot_cfg() -> EntityCfg:\n",
        "  \"\"\"Get a fresh CartPole robot configuration instance.\"\"\"\n",
        "  actuators = (\n",
        "    XmlVelocityActuatorCfg(\n",
        "      joint_names_expr=(\"slide\",),\n",
        "    ),\n",
        "  )\n",
        "  articulation = EntityArticulationInfoCfg(actuators=actuators)\n",
        "  return EntityCfg(\n",
        "    spec_fn=get_spec,\n",
        "    articulation=articulation\n",
        "  )\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   import mujoco.viewer as viewer\n",
        "#   robot = Entity(get_cartpole_robot_cfg())\n",
        "#   viewer.launch(robot.spec.compile())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WSaDod04FwN",
        "outputId": "1bfa64e4-e429-4db2-f8f4-9299f675326e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/__init__.py\n"
          ]
        }
      ],
      "source": [
        "# Create __init__.py for the cartpole robot package\n",
        "%%writefile /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/__init__.py\n",
        "# Empty __init__.py to mark the directory as a Python package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "W1tiBPfp_oVP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Append src dir to python path\n",
        "mjlab_src = '/content/mjlab/src'\n",
        "if mjlab_src not in sys.path:\n",
        "    sys.path.insert(0, mjlab_src)\n",
        "    print(f\"‚úì Added {mjlab_src} to Python path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToWF84qC4Hfg"
      },
      "source": [
        "### **‚úÖ Verify Robot Setup**\n",
        "\n",
        "Let's test that the robot can be loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tVsvqzQ4J9h",
        "outputId": "1b4e175f-f9ae-4f8d-a4e2-a231df16ac3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì CartPole robot loaded successfully!\n",
            "  ‚Ä¢ Degrees of Freedom (DOF): 2\n",
            "  ‚Ä¢ Number of Actuators: 1\n",
            "  ‚Ä¢ Bodies: 4\n",
            "  ‚Ä¢ Joints: 2\n"
          ]
        }
      ],
      "source": [
        "from mjlab.entity import Entity\n",
        "from mjlab.asset_zoo.robots.cartpole.cartpole_constants import get_cartpole_robot_cfg\n",
        "\n",
        "# Load the robot\n",
        "robot = Entity(get_cartpole_robot_cfg())\n",
        "model = robot.spec.compile()\n",
        "\n",
        "# Display robot information\n",
        "print(\"‚úì CartPole robot loaded successfully!\")\n",
        "print(f\"  ‚Ä¢ Degrees of Freedom (DOF): {model.nv}\")\n",
        "print(f\"  ‚Ä¢ Number of Actuators: {model.nu}\")\n",
        "print(f\"  ‚Ä¢ Bodies: {model.nbody}\")\n",
        "print(f\"  ‚Ä¢ Joints: {model.njnt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2_9dixlHON1"
      },
      "source": [
        "### **üìã Register the Robot**\n",
        "\n",
        "Add the CartPole robot to the asset zoo registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qDIF__lHPcb",
        "outputId": "e56aa931-2da9-4d05-a887-811a66f75cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì CartPole robot registered in asset zoo\n"
          ]
        }
      ],
      "source": [
        "# Add CartPole import to robots __init__.py\n",
        "with open('/content/mjlab/src/mjlab/asset_zoo/robots/__init__.py', 'a') as f:\n",
        "    f.write('\\n# CartPole robot\\n')\n",
        "    f.write('from mjlab.asset_zoo.robots.cartpole.cartpole_constants import ')\n",
        "    f.write('get_cartpole_robot_cfg as get_cartpole_robot_cfg\\n')\n",
        "\n",
        "print(\"‚úì CartPole robot registered in asset zoo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lVD_L6PHWNm"
      },
      "source": [
        "---\n",
        "\n",
        "## **üéØ Step 2: Define the Task (MDP)**\n",
        "\n",
        "Now we'll define the Markov Decision Process:\n",
        "- **Observations**: pole angle, angular velocity, cart position, cart velocity\n",
        "- **Actions**: cart velocity commands\n",
        "- **Rewards**: upright reward + effort penalty\n",
        "- **Terminations**: pole tips over or timeout\n",
        "- **Events**: random pushes for robustness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQxe4TBrHb-I"
      },
      "source": [
        "### **üìÅ Create Task Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWBqdkziHc2G",
        "outputId": "fff2922f-71c9-4268-e03b-a03fcac945b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Task directory created\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/mjlab/src/mjlab/tasks/cartpole\n",
        "\n",
        "print(\"‚úì Task directory created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJfjPpm0Hhj1"
      },
      "source": [
        "### **üìù Create Environment Configuration**\n",
        "\n",
        "This file contains the MDP (Markov Decision Process) components:\n",
        "1. **Scene Config**: 64 parallel environments\n",
        "2. **Actions**: Joint velocity control with 20.0 scale\n",
        "3. **Observations**: Normalized state variables\n",
        "4. **Rewards**: Upright reward (5.0) + effort penalty (-0.01)\n",
        "5. **Events**: Joint resets + random pushes\n",
        "6. **Terminations**: Pole tipped (>30¬∞) or timeout (10s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "javx9XDIHkFI",
        "outputId": "2d3fc71b-125e-43c9-8cac-e961295ddb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/mjlab/src/mjlab/tasks/cartpole/env_cfg.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/tasks/cartpole/env_cfg.py\n",
        "\"\"\"CartPole task environment configuration.\"\"\"\n",
        "\n",
        "import math\n",
        "import torch\n",
        "\n",
        "from mjlab.envs import ManagerBasedRlEnvCfg\n",
        "from mjlab.envs.mdp.actions import JointVelocityActionCfg\n",
        "from mjlab.managers.manager_term_config import (\n",
        "  ObservationGroupCfg,\n",
        "  ObservationTermCfg,\n",
        "  RewardTermCfg,\n",
        "  TerminationTermCfg,\n",
        "  EventTermCfg,\n",
        ")\n",
        "from mjlab.managers.scene_entity_config import SceneEntityCfg\n",
        "from mjlab.scene import SceneCfg\n",
        "from mjlab.sim import MujocoCfg, SimulationCfg\n",
        "from mjlab.viewer import ViewerConfig\n",
        "from mjlab.asset_zoo.robots.cartpole.cartpole_constants import get_cartpole_robot_cfg\n",
        "from mjlab.envs import mdp\n",
        "\n",
        "\n",
        "def cartpole_env_cfg(play: bool = False) -> ManagerBasedRlEnvCfg:\n",
        "  \"\"\"Create CartPole environment configuration.\n",
        "\n",
        "  Args:\n",
        "    play: If True, disables corruption and extends episode length for evaluation.\n",
        "  \"\"\"\n",
        "\n",
        "  # ==============================================================================\n",
        "  # Scene Configuration\n",
        "  # ==============================================================================\n",
        "\n",
        "  scene_cfg = SceneCfg(\n",
        "    num_envs=64 if not play else 16,  # Fewer envs for play mode\n",
        "    extent=1.0,   # Spacing between environments\n",
        "    entities={\"robot\": get_cartpole_robot_cfg()},\n",
        "  )\n",
        "\n",
        "  viewer_cfg = ViewerConfig(\n",
        "    origin_type=ViewerConfig.OriginType.ASSET_BODY,\n",
        "    asset_name=\"robot\",\n",
        "    body_name=\"pole\",\n",
        "    distance=3.0,\n",
        "    elevation=10.0,\n",
        "    azimuth=90.0,\n",
        "  )\n",
        "\n",
        "  sim_cfg = SimulationCfg(\n",
        "    mujoco=MujocoCfg(\n",
        "      timestep=0.02,  # 50 Hz control\n",
        "      iterations=1,\n",
        "    ),\n",
        "  )\n",
        "\n",
        "  # ==============================================================================\n",
        "  # Actions\n",
        "  # ==============================================================================\n",
        "\n",
        "  actions = {\n",
        "    \"joint_pos\": JointVelocityActionCfg(\n",
        "      asset_name=\"robot\",\n",
        "      actuator_names=(\".*\",),\n",
        "      scale=20.0,\n",
        "      use_default_offset=False,\n",
        "    ),\n",
        "  }\n",
        "\n",
        "  # ==============================================================================\n",
        "  # Observations\n",
        "  # ==============================================================================\n",
        "\n",
        "  policy_terms = {\n",
        "    \"angle\": ObservationTermCfg(\n",
        "      func=lambda env: env.sim.data.qpos[:, 1:2] / math.pi\n",
        "    ),\n",
        "    \"ang_vel\": ObservationTermCfg(\n",
        "      func=lambda env: env.sim.data.qvel[:, 1:2] / 5.0\n",
        "    ),\n",
        "    \"cart_pos\": ObservationTermCfg(\n",
        "      func=lambda env: env.sim.data.qpos[:, 0:1] / 2.0\n",
        "    ),\n",
        "    \"cart_vel\": ObservationTermCfg(\n",
        "      func=lambda env: env.sim.data.qvel[:, 0:1] / 20.0\n",
        "    ),\n",
        "  }\n",
        "\n",
        "  observations = {\n",
        "    \"policy\": ObservationGroupCfg(\n",
        "      terms=policy_terms,\n",
        "      concatenate_terms=True,\n",
        "      enable_corruption=not play,  # Disable corruption in play mode\n",
        "    ),\n",
        "    \"critic\": ObservationGroupCfg(\n",
        "      terms=policy_terms,  # Critic uses same observations\n",
        "      concatenate_terms=True,\n",
        "      enable_corruption=False,\n",
        "    ),\n",
        "  }\n",
        "\n",
        "  # ==============================================================================\n",
        "  # Rewards\n",
        "  # ==============================================================================\n",
        "\n",
        "  def compute_upright_reward(env):\n",
        "    \"\"\"Reward for keeping pole upright (cosine of angle).\"\"\"\n",
        "    return env.sim.data.qpos[:, 1].cos()\n",
        "\n",
        "  def compute_effort_penalty(env):\n",
        "    \"\"\"Penalty for control effort.\"\"\"\n",
        "    return -0.01 * (env.sim.data.ctrl[:, 0] ** 2)\n",
        "\n",
        "  rewards = {\n",
        "    \"upright\": RewardTermCfg(func=compute_upright_reward, weight=5.0),\n",
        "    \"effort\": RewardTermCfg(func=compute_effort_penalty, weight=1.0),\n",
        "  }\n",
        "\n",
        "  # ==============================================================================\n",
        "  # Events\n",
        "  # ==============================================================================\n",
        "\n",
        "  def random_push_cart(env, env_ids, force_range=(-5, 5)):\n",
        "    \"\"\"Apply random force to cart for robustness training.\"\"\"\n",
        "    n = len(env_ids)\n",
        "    random_forces = (\n",
        "      torch.rand(n, device=env.device) *\n",
        "      (force_range[1] - force_range[0]) +\n",
        "      force_range[0]\n",
        "    )\n",
        "    env.sim.data.qfrc_applied[env_ids, 0] = random_forces\n",
        "\n",
        "  events = {\n",
        "    \"reset_robot_joints\": EventTermCfg(\n",
        "      func=mdp.reset_joints_by_offset,\n",
        "      mode=\"reset\",\n",
        "      params={\n",
        "        \"asset_cfg\": SceneEntityCfg(\"robot\"),\n",
        "        \"position_range\": (-0.1, 0.1),\n",
        "        \"velocity_range\": (-0.1, 0.1),\n",
        "      },\n",
        "    ),\n",
        "  }\n",
        "\n",
        "  # Add random pushes only in training mode\n",
        "  if not play:\n",
        "    events[\"random_push\"] = EventTermCfg(\n",
        "      func=random_push_cart,\n",
        "      mode=\"interval\",\n",
        "      interval_range_s=(1.0, 2.0),\n",
        "      params={\"force_range\": (-20.0, 20.0)},\n",
        "    )\n",
        "\n",
        "  # ==============================================================================\n",
        "  # Terminations\n",
        "  # ==============================================================================\n",
        "\n",
        "  def check_pole_tipped(env):\n",
        "    \"\"\"Check if pole has tipped beyond 30 degrees.\"\"\"\n",
        "    return env.sim.data.qpos[:, 1].abs() > math.radians(30)\n",
        "\n",
        "  terminations = {\n",
        "    \"timeout\": TerminationTermCfg(func=mdp.time_out, time_out=True),\n",
        "    \"tipped\": TerminationTermCfg(func=check_pole_tipped, time_out=False),\n",
        "  }\n",
        "\n",
        "  # ==============================================================================\n",
        "  # Environment Configuration\n",
        "  # ==============================================================================\n",
        "\n",
        "  return ManagerBasedRlEnvCfg(\n",
        "    scene=scene_cfg,\n",
        "    observations=observations,\n",
        "    actions=actions,\n",
        "    rewards=rewards,\n",
        "    events=events,\n",
        "    terminations=terminations,\n",
        "    sim=sim_cfg,\n",
        "    viewer=viewer_cfg,\n",
        "    decimation=1,           # No action repeat\n",
        "    episode_length_s=int(1e9) if play else 10.0,  # Infinite for play, 10s for training\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5maMjzSj_X"
      },
      "source": [
        "### **‚öôÔ∏è Create RL Configuration**\n",
        "\n",
        "This file defines the PPO (Proximal Policy Optimization) training parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C81zZm6mSj_X",
        "outputId": "9faf6008-c137-47e6-a68b-f50a8011210e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/mjlab/src/mjlab/tasks/cartpole/rl_cfg.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/tasks/cartpole/rl_cfg.py\n",
        "\"\"\"RL configuration for CartPole task.\"\"\"\n",
        "\n",
        "from mjlab.rl.config import (\n",
        "  RslRlOnPolicyRunnerCfg,\n",
        "  RslRlPpoActorCriticCfg,\n",
        "  RslRlPpoAlgorithmCfg,\n",
        ")\n",
        "\n",
        "\n",
        "def cartpole_ppo_runner_cfg() -> RslRlOnPolicyRunnerCfg:\n",
        "  \"\"\"Create RL runner configuration for CartPole task.\"\"\"\n",
        "  return RslRlOnPolicyRunnerCfg(\n",
        "    policy=RslRlPpoActorCriticCfg(\n",
        "      init_noise_std=1.0,\n",
        "      actor_obs_normalization=True,\n",
        "      critic_obs_normalization=True,\n",
        "      actor_hidden_dims=(256, 128, 64),  # Smaller network for simpler task\n",
        "      critic_hidden_dims=(256, 128, 64),\n",
        "      activation=\"elu\",\n",
        "    ),\n",
        "    algorithm=RslRlPpoAlgorithmCfg(\n",
        "      value_loss_coef=1.0,\n",
        "      use_clipped_value_loss=True,\n",
        "      clip_param=0.2,\n",
        "      entropy_coef=0.01,\n",
        "      num_learning_epochs=5,\n",
        "      num_mini_batches=4,\n",
        "      learning_rate=1.0e-3,\n",
        "      schedule=\"adaptive\",\n",
        "      gamma=0.99,\n",
        "      lam=0.95,\n",
        "      desired_kl=0.01,\n",
        "      max_grad_norm=1.0,\n",
        "    ),\n",
        "    experiment_name=\"cartpole\",\n",
        "    save_interval=50,\n",
        "    num_steps_per_env=24,\n",
        "    max_iterations=5_000,  # Fewer iterations for simpler task\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc8-AHGcHt78"
      },
      "source": [
        "### **üìã Register the Task Environment**\n",
        "\n",
        "Register the CartPole task with mjlab registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YitUGUBRHxD4",
        "outputId": "387fe50e-f082-4d88-ffdc-2e6741ec1eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/mjlab/src/mjlab/tasks/cartpole/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/tasks/cartpole/__init__.py\n",
        "\"\"\"CartPole task registration.\"\"\"\n",
        "\n",
        "from mjlab.tasks.registry import register_mjlab_task\n",
        "from mjlab.tasks.velocity.rl import VelocityOnPolicyRunner\n",
        "\n",
        "from .env_cfg import cartpole_env_cfg\n",
        "from .rl_cfg import cartpole_ppo_runner_cfg\n",
        "\n",
        "register_mjlab_task(\n",
        "  task_id=\"Mjlab-Cartpole\",\n",
        "  env_cfg=cartpole_env_cfg(),\n",
        "  play_env_cfg=cartpole_env_cfg(play=True),\n",
        "  rl_cfg=cartpole_ppo_runner_cfg(),\n",
        "  runner_cls=VelocityOnPolicyRunner,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "-tV5SxDFH3MT"
      },
      "outputs": [],
      "source": [
        "# # Add CartPole task import to tasks __init__.py\n",
        "# with open('/content/mjlab/src/mjlab/tasks/__init__.py', 'a') as f:\n",
        "#     f.write('\\n# CartPole task\\n')\n",
        "#     f.write('from mjlab.tasks import cartpole\\n')\n",
        "\n",
        "# print(\"‚úì CartPole task registered\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Wbb7VOv2KD-F"
      },
      "outputs": [],
      "source": [
        "# # Reload mjlab as an editable package\n",
        "# %cd /content/mjlab\n",
        "# !uv pip install --system -e .\n",
        "\n",
        "# import importlib\n",
        "# import mjlab.tasks.cartpole\n",
        "\n",
        "# importlib.reload(mjlab.tasks)\n",
        "# importlib.reload(mjlab.tasks.cartpole)\n",
        "# importlib.reload(mjlab.asset_zoo.robots.cartpole)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyJpGMP4H6rN"
      },
      "source": [
        "### **‚úÖ Verify Environment Registration**\n",
        "\n",
        "Let's test that the environment is properly registered and can be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "g7q0NH0rLm4_"
      },
      "outputs": [],
      "source": [
        "# import gymnasium as gym\n",
        "# from mjlab.tasks import cartpole\n",
        "\n",
        "# # Check if environment is registered\n",
        "# from mjlab.tasks.registry import list_tasks\n",
        "\n",
        "# available_tasks = list_tasks()\n",
        "# if \"Mjlab-Cartpole\" in available_tasks:\n",
        "#     print(\"‚úì Mjlab-Cartpole environment successfully registered!\\n\")\n",
        "\n",
        "#     # Create a test environment\n",
        "#     env = gym.make(\"Mjlab-Cartpole\", headless=True)\n",
        "\n",
        "#     print(\"Environment Details:\")\n",
        "#     print(f\"  ‚Ä¢ Observation space: {env.observation_space}\")\n",
        "#     print(f\"  ‚Ä¢ Action space: {env.action_space}\")\n",
        "#     print(f\"  ‚Ä¢ Number of environments: {env.unwrapped.num_envs}\")\n",
        "\n",
        "#     # Test a step\n",
        "#     obs, info = env.reset()\n",
        "#     print(f\"\\n  ‚Ä¢ Observation shape: {obs['policy'].shape}\")\n",
        "#     print(f\"  ‚Ä¢ Sample observation: {obs['policy'][0]}\")\n",
        "\n",
        "#     env.close()\n",
        "#     print(\"\\n‚úì Environment test completed successfully!\")\n",
        "# else:\n",
        "#     print(\"‚úó Environment not found in registry\")\n",
        "#     print(\"Available environments:\")\n",
        "#     for task in available_tasks:\n",
        "#         print(f\"  ‚Ä¢ {task}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7wqLZR1rnGn"
      },
      "source": [
        "---\n",
        "\n",
        "## **üöÄ Step 3: Train the Agent**\n",
        "\n",
        "Now let's train a PPO policy to balance the CartPole!\n",
        "\n",
        "**Training Configuration:**\n",
        "- Algorithm: PPO (Proximal Policy Optimization)\n",
        "- Parallel Environments: 64\n",
        "- Episode Length: 10 seconds (500 steps @ 50Hz)\n",
        "- Total Steps: ~5-10 million (adjust as needed)\n",
        "\n",
        "‚ö†Ô∏è You may need to create a project named \"mjlab\" on wandb UI manually, since google colab doesn't have permission to create a new project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hht_hF4trqP2",
        "outputId": "ff35d341-ca0a-4168-8b5a-b9cd088aa3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:39\n",
            "                                    ETA: 00:00:50\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4773/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7332864 \n",
            "                       Steps per second: 7335 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0117\n",
            "                      Mean entropy loss: -3.4853\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:39\n",
            "                                    ETA: 00:00:50\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4774/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7334400 \n",
            "                       Steps per second: 7385 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0007\n",
            "                      Mean entropy loss: -3.4922\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0055\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:39\n",
            "                                    ETA: 00:00:49\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4775/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7335936 \n",
            "                       Steps per second: 7213 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0023\n",
            "                      Mean entropy loss: -3.5310\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0054\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:39\n",
            "                                    ETA: 00:00:49\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4776/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7337472 \n",
            "                       Steps per second: 7054 \n",
            "                        Collection time: 0.111s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0141\n",
            "                      Mean entropy loss: -3.5128\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.4167\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:40\n",
            "                                    ETA: 00:00:49\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4777/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7339008 \n",
            "                       Steps per second: 7462 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0032\n",
            "                      Mean entropy loss: -3.5350\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.1667\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:40\n",
            "                                    ETA: 00:00:49\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4778/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7340544 \n",
            "                       Steps per second: 7698 \n",
            "                        Collection time: 0.090s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0061\n",
            "                      Mean entropy loss: -3.5468\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9983\n",
            "                  Episode_Reward/effort: -0.0061\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:40\n",
            "                                    ETA: 00:00:49\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4779/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7342080 \n",
            "                       Steps per second: 7587 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0091\n",
            "                      Mean entropy loss: -3.5310\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9982\n",
            "                  Episode_Reward/effort: -0.0061\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:40\n",
            "                                    ETA: 00:00:48\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4780/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7343616 \n",
            "                       Steps per second: 7711 \n",
            "                        Collection time: 0.091s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0103\n",
            "                      Mean entropy loss: -3.5099\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0057\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:40\n",
            "                                    ETA: 00:00:48\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4781/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7345152 \n",
            "                       Steps per second: 7078 \n",
            "                        Collection time: 0.109s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0060\n",
            "                      Mean entropy loss: -3.5348\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:41\n",
            "                                    ETA: 00:00:48\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4782/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7346688 \n",
            "                       Steps per second: 7536 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.104s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0028\n",
            "                      Mean entropy loss: -3.5332\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:41\n",
            "                                    ETA: 00:00:48\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4783/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7348224 \n",
            "                       Steps per second: 6220 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.145s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0165\n",
            "                      Mean entropy loss: -3.5052\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.25s\n",
            "                           Time elapsed: 00:17:41\n",
            "                                    ETA: 00:00:47\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4784/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7349760 \n",
            "                       Steps per second: 5629 \n",
            "                        Collection time: 0.118s \n",
            "                          Learning time: 0.155s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0026\n",
            "                      Mean entropy loss: -3.5516\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9983\n",
            "                  Episode_Reward/effort: -0.0045\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:17:41\n",
            "                                    ETA: 00:00:47\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4785/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7351296 \n",
            "                       Steps per second: 5737 \n",
            "                        Collection time: 0.117s \n",
            "                          Learning time: 0.151s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0027\n",
            "                      Mean entropy loss: -3.5968\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9988\n",
            "                  Episode_Reward/effort: -0.0029\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:17:42\n",
            "                                    ETA: 00:00:47\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4786/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7352832 \n",
            "                       Steps per second: 6118 \n",
            "                        Collection time: 0.120s \n",
            "                          Learning time: 0.131s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0011\n",
            "                      Mean entropy loss: -3.6417\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.25s\n",
            "                           Time elapsed: 00:17:42\n",
            "                                    ETA: 00:00:47\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4787/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7354368 \n",
            "                       Steps per second: 5885 \n",
            "                        Collection time: 0.125s \n",
            "                          Learning time: 0.136s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0066\n",
            "                      Mean entropy loss: -3.6158\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.26s\n",
            "                           Time elapsed: 00:17:42\n",
            "                                    ETA: 00:00:47\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4788/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7355904 \n",
            "                       Steps per second: 5645 \n",
            "                        Collection time: 0.123s \n",
            "                          Learning time: 0.149s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0004\n",
            "                      Mean entropy loss: -3.6184\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0070\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:17:42\n",
            "                                    ETA: 00:00:46\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4789/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7357440 \n",
            "                       Steps per second: 4807 \n",
            "                        Collection time: 0.148s \n",
            "                          Learning time: 0.172s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0038\n",
            "                      Mean entropy loss: -3.6299\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9987\n",
            "                  Episode_Reward/effort: -0.0063\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.32s\n",
            "                           Time elapsed: 00:17:43\n",
            "                                    ETA: 00:00:46\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4790/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7358976 \n",
            "                       Steps per second: 6327 \n",
            "                        Collection time: 0.137s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0043\n",
            "                      Mean entropy loss: -3.6019\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.24s\n",
            "                           Time elapsed: 00:17:43\n",
            "                                    ETA: 00:00:46\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4791/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7360512 \n",
            "                       Steps per second: 7090 \n",
            "                        Collection time: 0.109s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0037\n",
            "                      Mean entropy loss: -3.5466\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0053\n",
            "            Episode_Termination/timeout: 1.4167\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:43\n",
            "                                    ETA: 00:00:46\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4792/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7362048 \n",
            "                       Steps per second: 7447 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0040\n",
            "                      Mean entropy loss: -3.5023\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0066\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:43\n",
            "                                    ETA: 00:00:45\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4793/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7363584 \n",
            "                       Steps per second: 6791 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.122s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0011\n",
            "                      Mean entropy loss: -3.5247\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.23s\n",
            "                           Time elapsed: 00:17:44\n",
            "                                    ETA: 00:00:45\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4794/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7365120 \n",
            "                       Steps per second: 7485 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0039\n",
            "                      Mean entropy loss: -3.5856\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9984\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:44\n",
            "                                    ETA: 00:00:45\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4795/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7366656 \n",
            "                       Steps per second: 7370 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0092\n",
            "                      Mean entropy loss: -3.5242\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0057\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:44\n",
            "                                    ETA: 00:00:45\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4796/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7368192 \n",
            "                       Steps per second: 7373 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0014\n",
            "                      Mean entropy loss: -3.6218\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0038\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:44\n",
            "                                    ETA: 00:00:45\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4797/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7369728 \n",
            "                       Steps per second: 7461 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0098\n",
            "                      Mean entropy loss: -3.5997\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9989\n",
            "                  Episode_Reward/effort: -0.0052\n",
            "            Episode_Termination/timeout: 1.5833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:44\n",
            "                                    ETA: 00:00:44\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4798/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7371264 \n",
            "                       Steps per second: 6864 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.123s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0093\n",
            "                      Mean entropy loss: -3.6597\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9985\n",
            "                  Episode_Reward/effort: -0.0073\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:45\n",
            "                                    ETA: 00:00:44\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4799/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7372800 \n",
            "                       Steps per second: 7852 \n",
            "                        Collection time: 0.091s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0059\n",
            "                      Mean entropy loss: -3.6549\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0053\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:45\n",
            "                                    ETA: 00:00:44\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4800/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7374336 \n",
            "                       Steps per second: 7418 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0012\n",
            "                      Mean entropy loss: -3.6407\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:45\n",
            "                                    ETA: 00:00:44\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4801/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7375872 \n",
            "                       Steps per second: 7329 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0028\n",
            "                      Mean entropy loss: -3.6271\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:45\n",
            "                                    ETA: 00:00:43\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4802/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7377408 \n",
            "                       Steps per second: 6965 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.117s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0084\n",
            "                      Mean entropy loss: -3.6010\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:45\n",
            "                                    ETA: 00:00:43\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4803/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7378944 \n",
            "                       Steps per second: 5976 \n",
            "                        Collection time: 0.131s \n",
            "                          Learning time: 0.126s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0113\n",
            "                      Mean entropy loss: -3.5564\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.26s\n",
            "                           Time elapsed: 00:17:46\n",
            "                                    ETA: 00:00:43\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4804/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7380480 \n",
            "                       Steps per second: 7189 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0015\n",
            "                      Mean entropy loss: -3.5361\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0052\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:46\n",
            "                                    ETA: 00:00:43\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4805/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7382016 \n",
            "                       Steps per second: 7742 \n",
            "                        Collection time: 0.093s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0013\n",
            "                      Mean entropy loss: -3.5593\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:46\n",
            "                                    ETA: 00:00:43\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4806/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7383552 \n",
            "                       Steps per second: 7677 \n",
            "                        Collection time: 0.094s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0013\n",
            "                      Mean entropy loss: -3.5795\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:46\n",
            "                                    ETA: 00:00:42\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4807/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7385088 \n",
            "                       Steps per second: 7088 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.117s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0034\n",
            "                      Mean entropy loss: -3.4725\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0062\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:47\n",
            "                                    ETA: 00:00:42\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4808/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7386624 \n",
            "                       Steps per second: 7798 \n",
            "                        Collection time: 0.092s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0029\n",
            "                      Mean entropy loss: -3.5532\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9989\n",
            "                  Episode_Reward/effort: -0.0066\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:47\n",
            "                                    ETA: 00:00:42\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4809/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7388160 \n",
            "                       Steps per second: 7450 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0008\n",
            "                      Mean entropy loss: -3.6180\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0061\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:47\n",
            "                                    ETA: 00:00:42\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4810/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7389696 \n",
            "                       Steps per second: 7483 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0042\n",
            "                      Mean entropy loss: -3.6065\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0038\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:47\n",
            "                                    ETA: 00:00:41\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4811/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7391232 \n",
            "                       Steps per second: 7532 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0084\n",
            "                      Mean entropy loss: -3.5898\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0036\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:47\n",
            "                                    ETA: 00:00:41\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4812/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7392768 \n",
            "                       Steps per second: 6920 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.119s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0077\n",
            "                      Mean entropy loss: -3.5866\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.4167\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:48\n",
            "                                    ETA: 00:00:41\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4813/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7394304 \n",
            "                       Steps per second: 7400 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0071\n",
            "                      Mean entropy loss: -3.6234\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0036\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:48\n",
            "                                    ETA: 00:00:41\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4814/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7395840 \n",
            "                       Steps per second: 7563 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0022\n",
            "                      Mean entropy loss: -3.6329\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9982\n",
            "                  Episode_Reward/effort: -0.0076\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:48\n",
            "                                    ETA: 00:00:41\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4815/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7397376 \n",
            "                       Steps per second: 7367 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0061\n",
            "                      Mean entropy loss: -3.6329\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0055\n",
            "            Episode_Termination/timeout: 1.1667\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:48\n",
            "                                    ETA: 00:00:40\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4816/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7398912 \n",
            "                       Steps per second: 7334 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0262\n",
            "                      Mean entropy loss: -3.5630\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0035\n",
            "            Episode_Termination/timeout: 1.1250\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:48\n",
            "                                    ETA: 00:00:40\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4817/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7400448 \n",
            "                       Steps per second: 6704 \n",
            "                        Collection time: 0.106s \n",
            "                          Learning time: 0.123s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0107\n",
            "                      Mean entropy loss: -3.5583\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0045\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.23s\n",
            "                           Time elapsed: 00:17:49\n",
            "                                    ETA: 00:00:40\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4818/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7401984 \n",
            "                       Steps per second: 7551 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0052\n",
            "                      Mean entropy loss: -3.5609\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.5833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:49\n",
            "                                    ETA: 00:00:40\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4819/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7403520 \n",
            "                       Steps per second: 7273 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0010\n",
            "                      Mean entropy loss: -3.5415\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0037\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:49\n",
            "                                    ETA: 00:00:39\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4820/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7405056 \n",
            "                       Steps per second: 7756 \n",
            "                        Collection time: 0.092s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0033\n",
            "                      Mean entropy loss: -3.6059\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:49\n",
            "                                    ETA: 00:00:39\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4821/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7406592 \n",
            "                       Steps per second: 7449 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0025\n",
            "                      Mean entropy loss: -3.6050\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0058\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:49\n",
            "                                    ETA: 00:00:39\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4822/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7408128 \n",
            "                       Steps per second: 7226 \n",
            "                        Collection time: 0.107s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0013\n",
            "                      Mean entropy loss: -3.6545\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0063\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:50\n",
            "                                    ETA: 00:00:39\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4823/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7409664 \n",
            "                       Steps per second: 7312 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0020\n",
            "                      Mean entropy loss: -3.7337\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0061\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:50\n",
            "                                    ETA: 00:00:39\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4824/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7411200 \n",
            "                       Steps per second: 7650 \n",
            "                        Collection time: 0.095s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0047\n",
            "                      Mean entropy loss: -3.7371\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0057\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:50\n",
            "                                    ETA: 00:00:38\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4825/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7412736 \n",
            "                       Steps per second: 7402 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0079\n",
            "                      Mean entropy loss: -3.7917\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0053\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:50\n",
            "                                    ETA: 00:00:38\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4826/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7414272 \n",
            "                       Steps per second: 7741 \n",
            "                        Collection time: 0.091s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0048\n",
            "                      Mean entropy loss: -3.7598\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0068\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:51\n",
            "                                    ETA: 00:00:38\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4827/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7415808 \n",
            "                       Steps per second: 7085 \n",
            "                        Collection time: 0.110s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0000\n",
            "                      Mean entropy loss: -3.7310\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:51\n",
            "                                    ETA: 00:00:38\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4828/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7417344 \n",
            "                       Steps per second: 7470 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0034\n",
            "                      Mean entropy loss: -3.7602\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:51\n",
            "                                    ETA: 00:00:37\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4829/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7418880 \n",
            "                       Steps per second: 7198 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.118s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0052\n",
            "                      Mean entropy loss: -3.6827\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0057\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:51\n",
            "                                    ETA: 00:00:37\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4830/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7420416 \n",
            "                       Steps per second: 7014 \n",
            "                        Collection time: 0.110s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0241\n",
            "                      Mean entropy loss: -3.7122\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:51\n",
            "                                    ETA: 00:00:37\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4831/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7421952 \n",
            "                       Steps per second: 7390 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0041\n",
            "                      Mean entropy loss: -3.6961\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9988\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:52\n",
            "                                    ETA: 00:00:37\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4832/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7423488 \n",
            "                       Steps per second: 7000 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.115s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: 0.0147\n",
            "                      Mean entropy loss: -3.6729\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0037\n",
            "            Episode_Termination/timeout: 1.0417\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:52\n",
            "                                    ETA: 00:00:37\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4833/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7425024 \n",
            "                       Steps per second: 7428 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: 0.0157\n",
            "                      Mean entropy loss: -3.6153\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.3750\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:52\n",
            "                                    ETA: 00:00:36\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4834/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7426560 \n",
            "                       Steps per second: 7152 \n",
            "                        Collection time: 0.108s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0020\n",
            "                      Mean entropy loss: -3.6329\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:52\n",
            "                                    ETA: 00:00:36\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4835/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7428096 \n",
            "                       Steps per second: 7602 \n",
            "                        Collection time: 0.094s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: -0.0031\n",
            "                      Mean entropy loss: -3.5962\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9989\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:52\n",
            "                                    ETA: 00:00:36\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4836/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7429632 \n",
            "                       Steps per second: 6316 \n",
            "                        Collection time: 0.105s \n",
            "                          Learning time: 0.138s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: 0.0101\n",
            "                      Mean entropy loss: -3.6799\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.24s\n",
            "                           Time elapsed: 00:17:53\n",
            "                                    ETA: 00:00:36\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4837/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7431168 \n",
            "                       Steps per second: 5389 \n",
            "                        Collection time: 0.133s \n",
            "                          Learning time: 0.152s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0002\n",
            "                      Mean entropy loss: -3.6876\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.28s\n",
            "                           Time elapsed: 00:17:53\n",
            "                                    ETA: 00:00:35\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4838/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7432704 \n",
            "                       Steps per second: 5672 \n",
            "                        Collection time: 0.135s \n",
            "                          Learning time: 0.136s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0049\n",
            "                      Mean entropy loss: -3.7619\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:17:53\n",
            "                                    ETA: 00:00:35\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4839/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7434240 \n",
            "                       Steps per second: 6013 \n",
            "                        Collection time: 0.122s \n",
            "                          Learning time: 0.134s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0010\n",
            "                      Mean entropy loss: -3.7350\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9989\n",
            "                  Episode_Reward/effort: -0.0054\n",
            "            Episode_Termination/timeout: 1.5833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.26s\n",
            "                           Time elapsed: 00:17:53\n",
            "                                    ETA: 00:00:35\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4840/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7435776 \n",
            "                       Steps per second: 6096 \n",
            "                        Collection time: 0.113s \n",
            "                          Learning time: 0.139s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0010\n",
            "                      Mean entropy loss: -3.7956\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0058\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.25s\n",
            "                           Time elapsed: 00:17:54\n",
            "                                    ETA: 00:00:35\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4841/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7437312 \n",
            "                       Steps per second: 5769 \n",
            "                        Collection time: 0.124s \n",
            "                          Learning time: 0.142s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0058\n",
            "                      Mean entropy loss: -3.6573\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9984\n",
            "                  Episode_Reward/effort: -0.0034\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:17:54\n",
            "                                    ETA: 00:00:35\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4842/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7438848 \n",
            "                       Steps per second: 4991 \n",
            "                        Collection time: 0.137s \n",
            "                          Learning time: 0.170s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0027\n",
            "                      Mean entropy loss: -3.6945\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9984\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.31s\n",
            "                           Time elapsed: 00:17:54\n",
            "                                    ETA: 00:00:34\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4843/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7440384 \n",
            "                       Steps per second: 5680 \n",
            "                        Collection time: 0.147s \n",
            "                          Learning time: 0.123s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0009\n",
            "                      Mean entropy loss: -3.6438\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9988\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:17:55\n",
            "                                    ETA: 00:00:34\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4844/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7441920 \n",
            "                       Steps per second: 7162 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0008\n",
            "                      Mean entropy loss: -3.7299\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9983\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:55\n",
            "                                    ETA: 00:00:34\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4845/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7443456 \n",
            "                       Steps per second: 7417 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0047\n",
            "                      Mean entropy loss: -3.5906\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9986\n",
            "                  Episode_Reward/effort: -0.0055\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:55\n",
            "                                    ETA: 00:00:34\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4846/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7444992 \n",
            "                       Steps per second: 7533 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0034\n",
            "                      Mean entropy loss: -3.5702\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0034\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:55\n",
            "                                    ETA: 00:00:33\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4847/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7446528 \n",
            "                       Steps per second: 7157 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0010\n",
            "                      Mean entropy loss: -3.5415\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9989\n",
            "                  Episode_Reward/effort: -0.0037\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:55\n",
            "                                    ETA: 00:00:33\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4848/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7448064 \n",
            "                       Steps per second: 6897 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.120s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0101\n",
            "                      Mean entropy loss: -3.6072\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:56\n",
            "                                    ETA: 00:00:33\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4849/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7449600 \n",
            "                       Steps per second: 6875 \n",
            "                        Collection time: 0.112s \n",
            "                          Learning time: 0.111s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0016\n",
            "                      Mean entropy loss: -3.4928\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0063\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:56\n",
            "                                    ETA: 00:00:33\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4850/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7451136 \n",
            "                       Steps per second: 7526 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0039\n",
            "                      Mean entropy loss: -3.4982\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0039\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:56\n",
            "                                    ETA: 00:00:33\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4851/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7452672 \n",
            "                       Steps per second: 7608 \n",
            "                        Collection time: 0.095s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0071\n",
            "                      Mean entropy loss: -3.4759\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0029\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:56\n",
            "                                    ETA: 00:00:32\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4852/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7454208 \n",
            "                       Steps per second: 7600 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.104s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: 0.0093\n",
            "                      Mean entropy loss: -3.5572\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:56\n",
            "                                    ETA: 00:00:32\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4853/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7455744 \n",
            "                       Steps per second: 7048 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.116s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0023\n",
            "                      Mean entropy loss: -3.4949\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.1250\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:57\n",
            "                                    ETA: 00:00:32\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4854/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7457280 \n",
            "                       Steps per second: 7517 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.103s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0003\n",
            "                      Mean entropy loss: -3.5368\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0052\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:57\n",
            "                                    ETA: 00:00:32\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4855/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7458816 \n",
            "                       Steps per second: 7473 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0050\n",
            "                      Mean entropy loss: -3.5456\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0031\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:57\n",
            "                                    ETA: 00:00:31\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4856/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7460352 \n",
            "                       Steps per second: 7602 \n",
            "                        Collection time: 0.095s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0013\n",
            "                      Mean entropy loss: -3.5567\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:57\n",
            "                                    ETA: 00:00:31\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4857/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7461888 \n",
            "                       Steps per second: 7321 \n",
            "                        Collection time: 0.105s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0013\n",
            "                      Mean entropy loss: -3.4866\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:58\n",
            "                                    ETA: 00:00:31\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4858/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7463424 \n",
            "                       Steps per second: 6973 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.121s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0020\n",
            "                      Mean entropy loss: -3.4796\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0055\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:58\n",
            "                                    ETA: 00:00:31\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4859/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7464960 \n",
            "                       Steps per second: 7421 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0003\n",
            "                      Mean entropy loss: -3.5381\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.0833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:58\n",
            "                                    ETA: 00:00:31\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4860/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7466496 \n",
            "                       Steps per second: 7564 \n",
            "                        Collection time: 0.095s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0029\n",
            "                      Mean entropy loss: -3.5735\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.5000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:58\n",
            "                                    ETA: 00:00:30\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4861/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7468032 \n",
            "                       Steps per second: 7101 \n",
            "                        Collection time: 0.105s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0012\n",
            "                      Mean entropy loss: -3.5640\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:58\n",
            "                                    ETA: 00:00:30\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4862/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7469568 \n",
            "                       Steps per second: 7874 \n",
            "                        Collection time: 0.089s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0092\n",
            "                      Mean entropy loss: -3.5962\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9988\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:59\n",
            "                                    ETA: 00:00:30\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4863/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7471104 \n",
            "                       Steps per second: 6963 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.123s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0004\n",
            "                      Mean entropy loss: -3.5835\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0066\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:17:59\n",
            "                                    ETA: 00:00:30\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4864/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7472640 \n",
            "                       Steps per second: 7555 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0099\n",
            "                      Mean entropy loss: -3.6944\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0054\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:17:59\n",
            "                                    ETA: 00:00:29\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4865/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7474176 \n",
            "                       Steps per second: 7470 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0016\n",
            "                      Mean entropy loss: -3.6916\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:59\n",
            "                                    ETA: 00:00:29\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4866/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7475712 \n",
            "                       Steps per second: 7251 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0062\n",
            "                      Mean entropy loss: -3.6628\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:17:59\n",
            "                                    ETA: 00:00:29\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4867/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7477248 \n",
            "                       Steps per second: 7335 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0193\n",
            "                      Mean entropy loss: -3.6408\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9984\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:00\n",
            "                                    ETA: 00:00:29\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4868/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7478784 \n",
            "                       Steps per second: 7369 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0191\n",
            "                      Mean entropy loss: -3.6562\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9986\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:00\n",
            "                                    ETA: 00:00:29\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4869/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7480320 \n",
            "                       Steps per second: 7479 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0018\n",
            "                      Mean entropy loss: -3.6447\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0031\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:00\n",
            "                                    ETA: 00:00:28\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4870/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7481856 \n",
            "                       Steps per second: 7657 \n",
            "                        Collection time: 0.094s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0046\n",
            "                      Mean entropy loss: -3.6444\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:00\n",
            "                                    ETA: 00:00:28\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4871/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7483392 \n",
            "                       Steps per second: 7547 \n",
            "                        Collection time: 0.093s \n",
            "                          Learning time: 0.111s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0006\n",
            "                      Mean entropy loss: -3.6617\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:00\n",
            "                                    ETA: 00:00:28\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4872/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7484928 \n",
            "                       Steps per second: 7535 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0060\n",
            "                      Mean entropy loss: -3.6189\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:01\n",
            "                                    ETA: 00:00:28\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4873/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7486464 \n",
            "                       Steps per second: 6994 \n",
            "                        Collection time: 0.114s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0021\n",
            "                      Mean entropy loss: -3.6347\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:01\n",
            "                                    ETA: 00:00:27\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4874/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7488000 \n",
            "                       Steps per second: 7461 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0048\n",
            "                      Mean entropy loss: -3.7450\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9977\n",
            "                  Episode_Reward/effort: -0.0061\n",
            "            Episode_Termination/timeout: 1.1667\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:01\n",
            "                                    ETA: 00:00:27\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4875/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7489536 \n",
            "                       Steps per second: 7325 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0033\n",
            "                      Mean entropy loss: -3.7226\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0050\n",
            "            Episode_Termination/timeout: 1.2500\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:01\n",
            "                                    ETA: 00:00:27\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4876/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7491072 \n",
            "                       Steps per second: 7598 \n",
            "                        Collection time: 0.094s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0000\n",
            "                      Mean entropy loss: -3.8243\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9987\n",
            "                  Episode_Reward/effort: -0.0059\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:01\n",
            "                                    ETA: 00:00:27\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4877/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7492608 \n",
            "                       Steps per second: 7380 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0041\n",
            "                      Mean entropy loss: -3.7528\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0060\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:02\n",
            "                                    ETA: 00:00:27\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4878/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7494144 \n",
            "                       Steps per second: 6829 \n",
            "                        Collection time: 0.113s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0095\n",
            "                      Mean entropy loss: -3.7967\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9989\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:02\n",
            "                                    ETA: 00:00:26\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4879/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7495680 \n",
            "                       Steps per second: 7523 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0023\n",
            "                      Mean entropy loss: -3.8026\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9987\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:02\n",
            "                                    ETA: 00:00:26\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4880/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7497216 \n",
            "                       Steps per second: 7277 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0033\n",
            "                      Mean entropy loss: -3.7979\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.2500\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:02\n",
            "                                    ETA: 00:00:26\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4881/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7498752 \n",
            "                       Steps per second: 7624 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0051\n",
            "                      Mean entropy loss: -3.7139\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.3333\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:03\n",
            "                                    ETA: 00:00:26\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4882/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7500288 \n",
            "                       Steps per second: 7430 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0020\n",
            "                      Mean entropy loss: -3.7156\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:03\n",
            "                                    ETA: 00:00:25\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4883/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7501824 \n",
            "                       Steps per second: 7295 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.111s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0024\n",
            "                      Mean entropy loss: -3.7376\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0045\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:03\n",
            "                                    ETA: 00:00:25\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4884/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7503360 \n",
            "                       Steps per second: 7606 \n",
            "                        Collection time: 0.095s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0003\n",
            "                    Mean surrogate loss: 0.0317\n",
            "                      Mean entropy loss: -3.7129\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9988\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:03\n",
            "                                    ETA: 00:00:25\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4885/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7504896 \n",
            "                       Steps per second: 7625 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0027\n",
            "                      Mean entropy loss: -3.7205\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:03\n",
            "                                    ETA: 00:00:25\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4886/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7506432 \n",
            "                       Steps per second: 7313 \n",
            "                        Collection time: 0.105s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0146\n",
            "                      Mean entropy loss: -3.7020\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:04\n",
            "                                    ETA: 00:00:25\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4887/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7507968 \n",
            "                       Steps per second: 7008 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.121s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0066\n",
            "                      Mean entropy loss: -3.7009\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0039\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:04\n",
            "                                    ETA: 00:00:24\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4888/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7509504 \n",
            "                       Steps per second: 7669 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0094\n",
            "                      Mean entropy loss: -3.6777\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0038\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:04\n",
            "                                    ETA: 00:00:24\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4889/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7511040 \n",
            "                       Steps per second: 7595 \n",
            "                        Collection time: 0.095s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0005\n",
            "                      Mean entropy loss: -3.6961\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:04\n",
            "                                    ETA: 00:00:24\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4890/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7512576 \n",
            "                       Steps per second: 5695 \n",
            "                        Collection time: 0.111s \n",
            "                          Learning time: 0.159s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0072\n",
            "                      Mean entropy loss: -3.7109\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:18:04\n",
            "                                    ETA: 00:00:24\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4891/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7514112 \n",
            "                       Steps per second: 5554 \n",
            "                        Collection time: 0.134s \n",
            "                          Learning time: 0.142s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0037\n",
            "                      Mean entropy loss: -3.6892\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0063\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.28s\n",
            "                           Time elapsed: 00:18:05\n",
            "                                    ETA: 00:00:23\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4892/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7515648 \n",
            "                       Steps per second: 5648 \n",
            "                        Collection time: 0.121s \n",
            "                          Learning time: 0.151s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0005\n",
            "                      Mean entropy loss: -3.6197\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0058\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:18:05\n",
            "                                    ETA: 00:00:23\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4893/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7517184 \n",
            "                       Steps per second: 5718 \n",
            "                        Collection time: 0.118s \n",
            "                          Learning time: 0.150s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0072\n",
            "                      Mean entropy loss: -3.6757\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:18:05\n",
            "                                    ETA: 00:00:23\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4894/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7518720 \n",
            "                       Steps per second: 5167 \n",
            "                        Collection time: 0.127s \n",
            "                          Learning time: 0.171s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0040\n",
            "                      Mean entropy loss: -3.6848\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9987\n",
            "                  Episode_Reward/effort: -0.0066\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.30s\n",
            "                           Time elapsed: 00:18:06\n",
            "                                    ETA: 00:00:23\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4895/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7520256 \n",
            "                       Steps per second: 4904 \n",
            "                        Collection time: 0.131s \n",
            "                          Learning time: 0.182s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0035\n",
            "                      Mean entropy loss: -3.6741\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.3333\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.31s\n",
            "                           Time elapsed: 00:18:06\n",
            "                                    ETA: 00:00:23\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4896/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7521792 \n",
            "                       Steps per second: 4839 \n",
            "                        Collection time: 0.146s \n",
            "                          Learning time: 0.172s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0015\n",
            "                      Mean entropy loss: -3.7136\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9988\n",
            "                  Episode_Reward/effort: -0.0059\n",
            "            Episode_Termination/timeout: 1.0833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.32s\n",
            "                           Time elapsed: 00:18:06\n",
            "                                    ETA: 00:00:22\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4897/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7523328 \n",
            "                       Steps per second: 7457 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0005\n",
            "                      Mean entropy loss: -3.7205\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0038\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:06\n",
            "                                    ETA: 00:00:22\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4898/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7524864 \n",
            "                       Steps per second: 7122 \n",
            "                        Collection time: 0.106s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0033\n",
            "                      Mean entropy loss: -3.7692\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:07\n",
            "                                    ETA: 00:00:22\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4899/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7526400 \n",
            "                       Steps per second: 7502 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0040\n",
            "                      Mean entropy loss: -3.7857\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0037\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:07\n",
            "                                    ETA: 00:00:22\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4900/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7527936 \n",
            "                       Steps per second: 7151 \n",
            "                        Collection time: 0.110s \n",
            "                          Learning time: 0.104s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0009\n",
            "                      Mean entropy loss: -3.7505\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:07\n",
            "                                    ETA: 00:00:21\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4901/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7529472 \n",
            "                       Steps per second: 7017 \n",
            "                        Collection time: 0.107s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0104\n",
            "                      Mean entropy loss: -3.7509\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.4167\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:07\n",
            "                                    ETA: 00:00:21\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4902/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7531008 \n",
            "                       Steps per second: 7201 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0038\n",
            "                      Mean entropy loss: -3.7302\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.1667\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:07\n",
            "                                    ETA: 00:00:21\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4903/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7532544 \n",
            "                       Steps per second: 7440 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0019\n",
            "                      Mean entropy loss: -3.7913\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0033\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:08\n",
            "                                    ETA: 00:00:21\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4904/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7534080 \n",
            "                       Steps per second: 7067 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.122s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0036\n",
            "                      Mean entropy loss: -3.7658\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9987\n",
            "                  Episode_Reward/effort: -0.0045\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:08\n",
            "                                    ETA: 00:00:21\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4905/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7535616 \n",
            "                       Steps per second: 7728 \n",
            "                        Collection time: 0.091s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0026\n",
            "                      Mean entropy loss: -3.7767\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:08\n",
            "                                    ETA: 00:00:20\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4906/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7537152 \n",
            "                       Steps per second: 7360 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0164\n",
            "                      Mean entropy loss: -3.7631\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0031\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:08\n",
            "                                    ETA: 00:00:20\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4907/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7538688 \n",
            "                       Steps per second: 7450 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0207\n",
            "                      Mean entropy loss: -3.8599\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:08\n",
            "                                    ETA: 00:00:20\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4908/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7540224 \n",
            "                       Steps per second: 7485 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0025\n",
            "                      Mean entropy loss: -3.8253\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:09\n",
            "                                    ETA: 00:00:20\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4909/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7541760 \n",
            "                       Steps per second: 7354 \n",
            "                        Collection time: 0.092s \n",
            "                          Learning time: 0.117s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0016\n",
            "                      Mean entropy loss: -3.8478\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9988\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:09\n",
            "                                    ETA: 00:00:19\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4910/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7543296 \n",
            "                       Steps per second: 7626 \n",
            "                        Collection time: 0.094s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0079\n",
            "                      Mean entropy loss: -3.8128\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:09\n",
            "                                    ETA: 00:00:19\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4911/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7544832 \n",
            "                       Steps per second: 7430 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.111s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0020\n",
            "                      Mean entropy loss: -3.8400\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0055\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:09\n",
            "                                    ETA: 00:00:19\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4912/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7546368 \n",
            "                       Steps per second: 7501 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0028\n",
            "                      Mean entropy loss: -3.9040\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:10\n",
            "                                    ETA: 00:00:19\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4913/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7547904 \n",
            "                       Steps per second: 7844 \n",
            "                        Collection time: 0.089s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0002\n",
            "                      Mean entropy loss: -3.9458\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:10\n",
            "                                    ETA: 00:00:19\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4914/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7549440 \n",
            "                       Steps per second: 6933 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.118s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0032\n",
            "                      Mean entropy loss: -3.9352\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0050\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:10\n",
            "                                    ETA: 00:00:18\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4915/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7550976 \n",
            "                       Steps per second: 7493 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0002\n",
            "                      Mean entropy loss: -3.9768\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:10\n",
            "                                    ETA: 00:00:18\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4916/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7552512 \n",
            "                       Steps per second: 7495 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.104s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0015\n",
            "                      Mean entropy loss: -4.0017\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0050\n",
            "            Episode_Termination/timeout: 1.4167\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:10\n",
            "                                    ETA: 00:00:18\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4917/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7554048 \n",
            "                       Steps per second: 7500 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0272\n",
            "                      Mean entropy loss: -3.9421\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:11\n",
            "                                    ETA: 00:00:18\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4918/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7555584 \n",
            "                       Steps per second: 7281 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0005\n",
            "                      Mean entropy loss: -3.9471\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:11\n",
            "                                    ETA: 00:00:17\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4919/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7557120 \n",
            "                       Steps per second: 7170 \n",
            "                        Collection time: 0.107s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0046\n",
            "                      Mean entropy loss: -3.9499\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0039\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:11\n",
            "                                    ETA: 00:00:17\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4920/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7558656 \n",
            "                       Steps per second: 7519 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0105\n",
            "                      Mean entropy loss: -3.8900\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0059\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:11\n",
            "                                    ETA: 00:00:17\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4921/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7560192 \n",
            "                       Steps per second: 7077 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.113s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0116\n",
            "                      Mean entropy loss: -3.8934\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:11\n",
            "                                    ETA: 00:00:17\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4922/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7561728 \n",
            "                       Steps per second: 7140 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.114s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0035\n",
            "                      Mean entropy loss: -3.8033\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.5833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:12\n",
            "                                    ETA: 00:00:17\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4923/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7563264 \n",
            "                       Steps per second: 7306 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0020\n",
            "                      Mean entropy loss: -3.9383\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:12\n",
            "                                    ETA: 00:00:16\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4924/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7564800 \n",
            "                       Steps per second: 7245 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0017\n",
            "                      Mean entropy loss: -3.9388\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:12\n",
            "                                    ETA: 00:00:16\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4925/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7566336 \n",
            "                       Steps per second: 7435 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.105s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0045\n",
            "                      Mean entropy loss: -3.9418\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:12\n",
            "                                    ETA: 00:00:16\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4926/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7567872 \n",
            "                       Steps per second: 7685 \n",
            "                        Collection time: 0.094s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.3558\n",
            "                      Mean entropy loss: -3.4688\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:12\n",
            "                                    ETA: 00:00:16\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4927/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7569408 \n",
            "                       Steps per second: 7404 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0016\n",
            "                      Mean entropy loss: -3.3323\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:13\n",
            "                                    ETA: 00:00:15\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4928/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7570944 \n",
            "                       Steps per second: 7141 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.116s \n",
            "                        Mean value loss: 0.0004\n",
            "                    Mean surrogate loss: 0.0073\n",
            "                      Mean entropy loss: -3.3972\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0053\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:13\n",
            "                                    ETA: 00:00:15\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4929/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7572480 \n",
            "                       Steps per second: 7397 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0088\n",
            "                    Mean surrogate loss: -0.0005\n",
            "                      Mean entropy loss: -3.3792\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0055\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:13\n",
            "                                    ETA: 00:00:15\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4930/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7574016 \n",
            "                       Steps per second: 7588 \n",
            "                        Collection time: 0.093s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0852\n",
            "                    Mean surrogate loss: 0.0050\n",
            "                      Mean entropy loss: -3.4461\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9986\n",
            "                  Episode_Reward/effort: -0.0052\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:13\n",
            "                                    ETA: 00:00:15\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4931/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7575552 \n",
            "                       Steps per second: 7576 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: 0.0107\n",
            "                      Mean entropy loss: -3.3478\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9982\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:13\n",
            "                                    ETA: 00:00:15\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4932/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7577088 \n",
            "                       Steps per second: 7437 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0003\n",
            "                    Mean surrogate loss: 0.0050\n",
            "                      Mean entropy loss: -3.4413\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0033\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:14\n",
            "                                    ETA: 00:00:14\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4933/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7578624 \n",
            "                       Steps per second: 7402 \n",
            "                        Collection time: 0.091s \n",
            "                          Learning time: 0.117s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0015\n",
            "                      Mean entropy loss: -3.5072\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:14\n",
            "                                    ETA: 00:00:14\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4934/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7580160 \n",
            "                       Steps per second: 7683 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.104s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0002\n",
            "                      Mean entropy loss: -3.5111\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:14\n",
            "                                    ETA: 00:00:14\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4935/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7581696 \n",
            "                       Steps per second: 7399 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0092\n",
            "                      Mean entropy loss: -3.3970\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:14\n",
            "                                    ETA: 00:00:14\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4936/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7583232 \n",
            "                       Steps per second: 7503 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0033\n",
            "                      Mean entropy loss: -3.3602\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0037\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:14\n",
            "                                    ETA: 00:00:13\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4937/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7584768 \n",
            "                       Steps per second: 7399 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0012\n",
            "                      Mean entropy loss: -3.3671\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0038\n",
            "            Episode_Termination/timeout: 1.4167\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:15\n",
            "                                    ETA: 00:00:13\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4938/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7586304 \n",
            "                       Steps per second: 6975 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.118s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: -0.0012\n",
            "                      Mean entropy loss: -3.3890\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:15\n",
            "                                    ETA: 00:00:13\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4939/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7587840 \n",
            "                       Steps per second: 7454 \n",
            "                        Collection time: 0.093s \n",
            "                          Learning time: 0.114s \n",
            "                        Mean value loss: 0.0002\n",
            "                    Mean surrogate loss: -0.0020\n",
            "                      Mean entropy loss: -3.4012\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0045\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:15\n",
            "                                    ETA: 00:00:13\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4940/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7589376 \n",
            "                       Steps per second: 6997 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.117s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: 0.0055\n",
            "                      Mean entropy loss: -3.3713\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.1667\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:15\n",
            "                                    ETA: 00:00:13\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4941/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7590912 \n",
            "                       Steps per second: 7609 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0020\n",
            "                      Mean entropy loss: -3.3921\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.1250\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:16\n",
            "                                    ETA: 00:00:12\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4942/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7592448 \n",
            "                       Steps per second: 7301 \n",
            "                        Collection time: 0.106s \n",
            "                          Learning time: 0.104s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0029\n",
            "                      Mean entropy loss: -3.5016\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:16\n",
            "                                    ETA: 00:00:12\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4943/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7593984 \n",
            "                       Steps per second: 6338 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.140s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0007\n",
            "                      Mean entropy loss: -3.4520\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.5833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.24s\n",
            "                           Time elapsed: 00:18:16\n",
            "                                    ETA: 00:00:12\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4944/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7595520 \n",
            "                       Steps per second: 5477 \n",
            "                        Collection time: 0.132s \n",
            "                          Learning time: 0.149s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0013\n",
            "                      Mean entropy loss: -3.3336\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.28s\n",
            "                           Time elapsed: 00:18:16\n",
            "                                    ETA: 00:00:12\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4945/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7597056 \n",
            "                       Steps per second: 6078 \n",
            "                        Collection time: 0.115s \n",
            "                          Learning time: 0.138s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0028\n",
            "                      Mean entropy loss: -3.3997\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9999\n",
            "                  Episode_Reward/effort: -0.0026\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.25s\n",
            "                           Time elapsed: 00:18:17\n",
            "                                    ETA: 00:00:11\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4946/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7598592 \n",
            "                       Steps per second: 6018 \n",
            "                        Collection time: 0.120s \n",
            "                          Learning time: 0.136s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0010\n",
            "                      Mean entropy loss: -3.3677\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0035\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.26s\n",
            "                           Time elapsed: 00:18:17\n",
            "                                    ETA: 00:00:11\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4947/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7600128 \n",
            "                       Steps per second: 5838 \n",
            "                        Collection time: 0.131s \n",
            "                          Learning time: 0.132s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0003\n",
            "                      Mean entropy loss: -3.4739\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0053\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.26s\n",
            "                           Time elapsed: 00:18:17\n",
            "                                    ETA: 00:00:11\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4948/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7601664 \n",
            "                       Steps per second: 5529 \n",
            "                        Collection time: 0.127s \n",
            "                          Learning time: 0.151s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0008\n",
            "                      Mean entropy loss: -3.3949\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0055\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.28s\n",
            "                           Time elapsed: 00:18:17\n",
            "                                    ETA: 00:00:11\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4949/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7603200 \n",
            "                       Steps per second: 4934 \n",
            "                        Collection time: 0.144s \n",
            "                          Learning time: 0.167s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0015\n",
            "                      Mean entropy loss: -3.3351\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.31s\n",
            "                           Time elapsed: 00:18:18\n",
            "                                    ETA: 00:00:11\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4950/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7604736 \n",
            "                       Steps per second: 5590 \n",
            "                        Collection time: 0.149s \n",
            "                          Learning time: 0.125s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0039\n",
            "                      Mean entropy loss: -3.3827\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:18:18\n",
            "                                    ETA: 00:00:10\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4951/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7606272 \n",
            "                       Steps per second: 7297 \n",
            "                        Collection time: 0.095s \n",
            "                          Learning time: 0.116s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0041\n",
            "                      Mean entropy loss: -3.3739\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0032\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:18\n",
            "                                    ETA: 00:00:10\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4952/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7607808 \n",
            "                       Steps per second: 7173 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.111s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0008\n",
            "                      Mean entropy loss: -3.4015\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0035\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:18\n",
            "                                    ETA: 00:00:10\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4953/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7609344 \n",
            "                       Steps per second: 7076 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.116s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0048\n",
            "                      Mean entropy loss: -3.3547\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0052\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:19\n",
            "                                    ETA: 00:00:10\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4954/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7610880 \n",
            "                       Steps per second: 6953 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.118s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0132\n",
            "                      Mean entropy loss: -3.3092\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0045\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:19\n",
            "                                    ETA: 00:00:09\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4955/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7612416 \n",
            "                       Steps per second: 6721 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.125s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0039\n",
            "                      Mean entropy loss: -3.4252\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9991\n",
            "                  Episode_Reward/effort: -0.0044\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.23s\n",
            "                           Time elapsed: 00:18:19\n",
            "                                    ETA: 00:00:09\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4956/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7613952 \n",
            "                       Steps per second: 7098 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.118s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0053\n",
            "                      Mean entropy loss: -3.4279\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:19\n",
            "                                    ETA: 00:00:09\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4957/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7615488 \n",
            "                       Steps per second: 7596 \n",
            "                        Collection time: 0.093s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0004\n",
            "                      Mean entropy loss: -3.5584\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0032\n",
            "            Episode_Termination/timeout: 1.0417\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:19\n",
            "                                    ETA: 00:00:09\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4958/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7617024 \n",
            "                       Steps per second: 7118 \n",
            "                        Collection time: 0.108s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0003\n",
            "                      Mean entropy loss: -3.5901\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0036\n",
            "            Episode_Termination/timeout: 1.3750\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:20\n",
            "                                    ETA: 00:00:09\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4959/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7618560 \n",
            "                       Steps per second: 7370 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0016\n",
            "                      Mean entropy loss: -3.6772\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0059\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:20\n",
            "                                    ETA: 00:00:08\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4960/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7620096 \n",
            "                       Steps per second: 7056 \n",
            "                        Collection time: 0.111s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0005\n",
            "                      Mean entropy loss: -3.7531\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9986\n",
            "                  Episode_Reward/effort: -0.0059\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:20\n",
            "                                    ETA: 00:00:08\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4961/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7621632 \n",
            "                       Steps per second: 7297 \n",
            "                        Collection time: 0.104s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0017\n",
            "                      Mean entropy loss: -3.8314\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9982\n",
            "                  Episode_Reward/effort: -0.0066\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:20\n",
            "                                    ETA: 00:00:08\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4962/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7623168 \n",
            "                       Steps per second: 7400 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0030\n",
            "                      Mean entropy loss: -3.8267\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:20\n",
            "                                    ETA: 00:00:08\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4963/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7624704 \n",
            "                       Steps per second: 6214 \n",
            "                        Collection time: 0.131s \n",
            "                          Learning time: 0.116s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0023\n",
            "                      Mean entropy loss: -3.8090\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0054\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.25s\n",
            "                           Time elapsed: 00:18:21\n",
            "                                    ETA: 00:00:07\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4964/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7626240 \n",
            "                       Steps per second: 7094 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.116s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0026\n",
            "                      Mean entropy loss: -3.8381\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0055\n",
            "            Episode_Termination/timeout: 1.5833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:21\n",
            "                                    ETA: 00:00:07\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4965/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7627776 \n",
            "                       Steps per second: 7405 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.112s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0004\n",
            "                      Mean entropy loss: -3.8125\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:21\n",
            "                                    ETA: 00:00:07\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4966/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7629312 \n",
            "                       Steps per second: 7540 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0028\n",
            "                      Mean entropy loss: -3.8321\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9986\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:21\n",
            "                                    ETA: 00:00:07\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4967/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7630848 \n",
            "                       Steps per second: 7540 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0046\n",
            "                      Mean entropy loss: -3.8263\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:22\n",
            "                                    ETA: 00:00:07\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4968/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7632384 \n",
            "                       Steps per second: 7114 \n",
            "                        Collection time: 0.103s \n",
            "                          Learning time: 0.113s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0134\n",
            "                      Mean entropy loss: -3.8526\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:22\n",
            "                                    ETA: 00:00:06\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4969/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7633920 \n",
            "                       Steps per second: 7046 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.116s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0013\n",
            "                      Mean entropy loss: -3.8975\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:22\n",
            "                                    ETA: 00:00:06\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4970/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7635456 \n",
            "                       Steps per second: 7364 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0098\n",
            "                      Mean entropy loss: -3.9132\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0038\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:22\n",
            "                                    ETA: 00:00:06\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4971/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7636992 \n",
            "                       Steps per second: 7455 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0030\n",
            "                      Mean entropy loss: -3.8514\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0036\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:22\n",
            "                                    ETA: 00:00:06\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4972/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7638528 \n",
            "                       Steps per second: 7462 \n",
            "                        Collection time: 0.093s \n",
            "                          Learning time: 0.113s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0007\n",
            "                      Mean entropy loss: -3.8750\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:23\n",
            "                                    ETA: 00:00:05\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4973/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7640064 \n",
            "                       Steps per second: 7320 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0008\n",
            "                      Mean entropy loss: -3.8266\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:23\n",
            "                                    ETA: 00:00:05\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4974/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7641600 \n",
            "                       Steps per second: 6633 \n",
            "                        Collection time: 0.112s \n",
            "                          Learning time: 0.120s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0103\n",
            "                      Mean entropy loss: -3.7726\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0050\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.23s\n",
            "                           Time elapsed: 00:18:23\n",
            "                                    ETA: 00:00:05\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4975/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7643136 \n",
            "                       Steps per second: 7627 \n",
            "                        Collection time: 0.094s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0057\n",
            "                      Mean entropy loss: -3.8656\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9996\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:23\n",
            "                                    ETA: 00:00:05\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4976/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7644672 \n",
            "                       Steps per second: 7440 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0001\n",
            "                      Mean entropy loss: -3.7327\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:23\n",
            "                                    ETA: 00:00:05\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4977/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7646208 \n",
            "                       Steps per second: 7504 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0029\n",
            "                      Mean entropy loss: -3.5087\n",
            "                            Mean reward: 49.94\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9993\n",
            "                  Episode_Reward/effort: -0.0047\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:24\n",
            "                                    ETA: 00:00:04\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4978/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7647744 \n",
            "                       Steps per second: 7407 \n",
            "                        Collection time: 0.101s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0001\n",
            "                      Mean entropy loss: -3.4863\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0036\n",
            "            Episode_Termination/timeout: 1.1250\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:24\n",
            "                                    ETA: 00:00:04\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4979/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7649280 \n",
            "                       Steps per second: 6894 \n",
            "                        Collection time: 0.111s \n",
            "                          Learning time: 0.111s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0057\n",
            "                      Mean entropy loss: -3.3758\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0038\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:24\n",
            "                                    ETA: 00:00:04\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4980/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7650816 \n",
            "                       Steps per second: 7311 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.110s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0026\n",
            "                      Mean entropy loss: -3.4511\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0045\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:24\n",
            "                                    ETA: 00:00:04\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4981/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7652352 \n",
            "                       Steps per second: 7439 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.108s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0027\n",
            "                      Mean entropy loss: -3.4698\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9999\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:25\n",
            "                                    ETA: 00:00:03\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4982/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7653888 \n",
            "                       Steps per second: 6980 \n",
            "                        Collection time: 0.109s \n",
            "                          Learning time: 0.111s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0022\n",
            "                      Mean entropy loss: -3.5031\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0042\n",
            "            Episode_Termination/timeout: 1.2917\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:25\n",
            "                                    ETA: 00:00:03\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4983/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7655424 \n",
            "                       Steps per second: 7547 \n",
            "                        Collection time: 0.098s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0010\n",
            "                    Mean surrogate loss: 0.0179\n",
            "                      Mean entropy loss: -3.5123\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0035\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:25\n",
            "                                    ETA: 00:00:03\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4984/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7656960 \n",
            "                       Steps per second: 6758 \n",
            "                        Collection time: 0.121s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0001\n",
            "                    Mean surrogate loss: 0.0027\n",
            "                      Mean entropy loss: -3.5007\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0051\n",
            "            Episode_Termination/timeout: 1.0833\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.23s\n",
            "                           Time elapsed: 00:18:25\n",
            "                                    ETA: 00:00:03\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4985/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7658496 \n",
            "                       Steps per second: 7677 \n",
            "                        Collection time: 0.093s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0032\n",
            "                      Mean entropy loss: -3.5214\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0040\n",
            "            Episode_Termination/timeout: 1.5000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:25\n",
            "                                    ETA: 00:00:03\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4986/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7660032 \n",
            "                       Steps per second: 7349 \n",
            "                        Collection time: 0.102s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0041\n",
            "                      Mean entropy loss: -3.5924\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:26\n",
            "                                    ETA: 00:00:02\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4987/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7661568 \n",
            "                       Steps per second: 7542 \n",
            "                        Collection time: 0.093s \n",
            "                          Learning time: 0.111s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0088\n",
            "                      Mean entropy loss: -3.5789\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9998\n",
            "                  Episode_Reward/effort: -0.0059\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:26\n",
            "                                    ETA: 00:00:02\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4988/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7663104 \n",
            "                       Steps per second: 7109 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.119s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0033\n",
            "                      Mean entropy loss: -3.7127\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0043\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:26\n",
            "                                    ETA: 00:00:02\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4989/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7664640 \n",
            "                       Steps per second: 7395 \n",
            "                        Collection time: 0.100s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0024\n",
            "                      Mean entropy loss: -3.7256\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0060\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:26\n",
            "                                    ETA: 00:00:02\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4990/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7666176 \n",
            "                       Steps per second: 7570 \n",
            "                        Collection time: 0.097s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0007\n",
            "                      Mean entropy loss: -3.7611\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0049\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:26\n",
            "                                    ETA: 00:00:01\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4991/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7667712 \n",
            "                       Steps per second: 7195 \n",
            "                        Collection time: 0.107s \n",
            "                          Learning time: 0.107s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0019\n",
            "                      Mean entropy loss: -3.8635\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.01\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0050\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:27\n",
            "                                    ETA: 00:00:01\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4992/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7669248 \n",
            "                       Steps per second: 7477 \n",
            "                        Collection time: 0.096s \n",
            "                          Learning time: 0.109s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0050\n",
            "                      Mean entropy loss: -3.8695\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0038\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:27\n",
            "                                    ETA: 00:00:01\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4993/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7670784 \n",
            "                       Steps per second: 7142 \n",
            "                        Collection time: 0.095s \n",
            "                          Learning time: 0.120s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0107\n",
            "                      Mean entropy loss: -3.9260\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9997\n",
            "                  Episode_Reward/effort: -0.0032\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.22s\n",
            "                           Time elapsed: 00:18:27\n",
            "                                    ETA: 00:00:01\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4994/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7672320 \n",
            "                       Steps per second: 7686 \n",
            "                        Collection time: 0.094s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0007\n",
            "                      Mean entropy loss: -3.9439\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9994\n",
            "                  Episode_Reward/effort: -0.0041\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.20s\n",
            "                           Time elapsed: 00:18:27\n",
            "                                    ETA: 00:00:01\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4995/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7673856 \n",
            "                       Steps per second: 7460 \n",
            "                        Collection time: 0.099s \n",
            "                          Learning time: 0.106s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0225\n",
            "                      Mean entropy loss: -3.9307\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0046\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.21s\n",
            "                           Time elapsed: 00:18:27\n",
            "                                    ETA: 00:00:00\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4996/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7675392 \n",
            "                       Steps per second: 6078 \n",
            "                        Collection time: 0.092s \n",
            "                          Learning time: 0.161s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0030\n",
            "                      Mean entropy loss: -3.8882\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9995\n",
            "                  Episode_Reward/effort: -0.0062\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.25s\n",
            "                           Time elapsed: 00:18:28\n",
            "                                    ETA: 00:00:00\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4997/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7676928 \n",
            "                       Steps per second: 5154 \n",
            "                        Collection time: 0.139s \n",
            "                          Learning time: 0.159s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0017\n",
            "                      Mean entropy loss: -3.9343\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9987\n",
            "                  Episode_Reward/effort: -0.0066\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.30s\n",
            "                           Time elapsed: 00:18:28\n",
            "                                    ETA: 00:00:00\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4998/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7678464 \n",
            "                       Steps per second: 5758 \n",
            "                        Collection time: 0.125s \n",
            "                          Learning time: 0.141s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: 0.0074\n",
            "                      Mean entropy loss: -3.9505\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9992\n",
            "                  Episode_Reward/effort: -0.0060\n",
            "            Episode_Termination/timeout: 1.0000\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.27s\n",
            "                           Time elapsed: 00:18:28\n",
            "                                    ETA: 00:00:00\n",
            "\n",
            "################################################################################\n",
            "\u001b[1m                          Learning iteration 4999/5000                          \u001b[0m \n",
            "\n",
            "                            Total steps: 7680000 \n",
            "                       Steps per second: 5984 \n",
            "                        Collection time: 0.123s \n",
            "                          Learning time: 0.134s \n",
            "                        Mean value loss: 0.0000\n",
            "                    Mean surrogate loss: -0.0016\n",
            "                      Mean entropy loss: -3.9829\n",
            "                            Mean reward: 49.95\n",
            "                    Mean episode length: 500.00\n",
            "                  Mean action noise std: 0.00\n",
            "                 Episode_Reward/upright: 4.9990\n",
            "                  Episode_Reward/effort: -0.0048\n",
            "            Episode_Termination/timeout: 1.1667\n",
            "             Episode_Termination/tipped: 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "                         Iteration time: 0.26s\n",
            "                           Time elapsed: 00:18:29\n",
            "                                    ETA: 00:00:00\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# This will take several minutes depending on your training configuration\n",
        "# !uv run train Mjlab-Cartpole\n",
        "# !python ./src/mjlab/scripts/train.py Mjlab-Cartpole --help\n",
        "!python /content/mjlab/src/mjlab/scripts/train.py Mjlab-Cartpole --agent.max-iterations 1000 --agent.save-interval 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCaqPznGrx8H"
      },
      "source": [
        "### **üìÅ Locate Training Checkpoints**\n",
        "\n",
        "After training, checkpoints are saved locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPnmHYu8r0uY",
        "outputId": "197a47a5-f101-48a7-d3cf-fbec3acd1a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Latest training run: 2025-12-05_17-02-08\n",
            "\n",
            "Found 101 checkpoints:\n",
            "  ‚Ä¢ model_750.pt (1.00 MB)\n",
            "  ‚Ä¢ model_800.pt (1.00 MB)\n",
            "  ‚Ä¢ model_850.pt (1.00 MB)\n",
            "  ‚Ä¢ model_900.pt (1.00 MB)\n",
            "  ‚Ä¢ model_950.pt (1.00 MB)\n",
            "\n",
            "üíæ Best checkpoint: logs/rsl_rl/cartpole/2025-12-05_17-02-08/model_950.pt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Find the most recent training run\n",
        "log_dir = Path(\"logs/rsl_rl/cartpole\")\n",
        "if log_dir.exists():\n",
        "    runs = sorted(log_dir.glob(\"*\"), key=os.path.getmtime, reverse=True)\n",
        "    if runs:\n",
        "        latest_run = runs[0]\n",
        "        print(f\"‚úì Latest training run: {latest_run.name}\\n\")\n",
        "\n",
        "        # List checkpoints\n",
        "        checkpoints = sorted(latest_run.glob(\"model_*.pt\"))\n",
        "        if checkpoints:\n",
        "            print(f\"Found {len(checkpoints)} checkpoints:\")\n",
        "            for ckpt in checkpoints[-5:]:  # Show last 5\n",
        "                size_mb = ckpt.stat().st_size / (1024 * 1024)\n",
        "                print(f\"  ‚Ä¢ {ckpt.name} ({size_mb:.2f} MB)\")\n",
        "\n",
        "            # Store the best checkpoint path\n",
        "            best_checkpoint = str(checkpoints[-1])\n",
        "            print(f\"\\nüíæ Best checkpoint: {best_checkpoint}\")\n",
        "        else:\n",
        "            print(\"‚ö† No checkpoints found yet\")\n",
        "    else:\n",
        "        print(\"‚ö† No training runs found\")\n",
        "else:\n",
        "    print(\"‚ö† Log directory not found. Have you run training yet?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWFS9Pw7r2uH"
      },
      "source": [
        "---\n",
        "\n",
        "## **üéÆ Step 4: Evaluate the Trained Policy**\n",
        "\n",
        "Let's test the trained policy! Since we're in Colab (headless), we can:\n",
        "1. Run the policy and print statistics\n",
        "2. Generate a video recording (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78PgHtpfr5sb"
      },
      "source": [
        "### **üéØ Run Policy Inference**\n",
        "\n",
        "Replace `<checkpoint_path>` with your actual checkpoint path from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9tGiFyBr2bW",
        "outputId": "56aab0d8-e5f8-44dd-e2b6-3cb2ec37ace6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Loading checkpoint: model_950.pt\n",
            "Warp 1.10.1 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.10.1\n",
            "Module mujoco_warp._src.smooth 9ca7ec0 load on device 'cuda:0' took 4.16 ms  (cached)\n",
            "Module mujoco_warp._src.collision_driver e72006d load on device 'cuda:0' took 0.35 ms  (cached)\n",
            "Module _nxn_broadphase__locals__kernel_1799b5b8 1799b5b load on device 'cuda:0' took 0.31 ms  (cached)\n",
            "Module mujoco_warp._src.collision_primitive._create_narrowphase_kernel f53bec7 load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "Module mujoco_warp._src.constraint fa42ba8 load on device 'cuda:0' took 1.20 ms  (cached)\n",
            "Module _actuator_velocity__locals__actuator_velocity_7933d235 876a329 load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module mujoco_warp._src.passive fc4f8e1 load on device 'cuda:0' took 0.56 ms  (cached)\n",
            "Module mujoco_warp._src.forward a88f545 load on device 'cuda:0' took 0.73 ms  (cached)\n",
            "Module mujoco_warp._src.support 769a44d load on device 'cuda:0' took 0.32 ms  (cached)\n",
            "Module _tile_cholesky_factorize_solve__locals__cholesky_factorize_solve_43a10bd2 d7e04e1 load on device 'cuda:0' took 35.70 ms  (cached)\n",
            "Module mujoco_warp._src.solver 1699532 load on device 'cuda:0' took 0.70 ms  (cached)\n",
            "Module mul_m_dense__locals___mul_m_dense_34acc5d2 6f70d43 load on device 'cuda:0' took 29.53 ms  (cached)\n",
            "Module update_constraint_gauss_cost__locals__kernel_fd0aa713 fd0aa71 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module update_gradient_JTDAJ_dense_tiled__locals__kernel_fcb58f0e 913eb00 load on device 'cuda:0' took 32.07 ms  (cached)\n",
            "Module update_gradient_cholesky__locals__kernel_b2b7bfef 2ca8f88 load on device 'cuda:0' took 37.30 ms  (cached)\n",
            "Module linesearch_jv_fused__locals__kernel_90eb52be 90eb52b load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Module mujoco_warp._src.derivative fda8455 load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "\n",
            "+---------------------------------+\n",
            "|         Base Environment        |\n",
            "+------------------------+--------+\n",
            "| Property               | Value  |\n",
            "+------------------------+--------+\n",
            "| Number of environments | 4      |\n",
            "| Environment device     | cuda:0 |\n",
            "| Environment seed       | None   |\n",
            "| Physics step-size      | 0.02   |\n",
            "| Environment step-size  | 0.02   |\n",
            "+------------------------+--------+\n",
            "\n",
            "[INFO] <EventManager> contains 1 active terms.\n",
            "+-------------------------------------+\n",
            "| Active Event Terms in Mode: 'reset' |\n",
            "+--------+----------------------------+\n",
            "| Index  | Name                       |\n",
            "+--------+----------------------------+\n",
            "|   0    | reset_robot_joints         |\n",
            "+--------+----------------------------+\n",
            "\n",
            "[INFO] <NullCommandManager> (inactive)\n",
            "[INFO] <ActionManager> contains 1 active terms.\n",
            "+--------------------------------+\n",
            "| Active Action Terms (shape: 1) |\n",
            "+-------+-----------+------------+\n",
            "| Index | Name      |  Dimension |\n",
            "+-------+-----------+------------+\n",
            "|   0   | joint_pos |          1 |\n",
            "+-------+-----------+------------+\n",
            "\n",
            "[INFO] <ObservationManager> contains 2 groups.\n",
            "+-----------------------------------------------------------+\n",
            "| Active Observation Terms in Group: 'policy' (shape: (4,)) |\n",
            "+----------------+------------------------+-----------------+\n",
            "|     Index      | Name                   |      Shape      |\n",
            "+----------------+------------------------+-----------------+\n",
            "|       0        | angle                  |       (1,)      |\n",
            "|       1        | ang_vel                |       (1,)      |\n",
            "|       2        | cart_pos               |       (1,)      |\n",
            "|       3        | cart_vel               |       (1,)      |\n",
            "+----------------+------------------------+-----------------+\n",
            "+-----------------------------------------------------------+\n",
            "| Active Observation Terms in Group: 'critic' (shape: (4,)) |\n",
            "+----------------+------------------------+-----------------+\n",
            "|     Index      | Name                   |      Shape      |\n",
            "+----------------+------------------------+-----------------+\n",
            "|       0        | angle                  |       (1,)      |\n",
            "|       1        | ang_vel                |       (1,)      |\n",
            "|       2        | cart_pos               |       (1,)      |\n",
            "|       3        | cart_vel               |       (1,)      |\n",
            "+----------------+------------------------+-----------------+\n",
            "\n",
            "[INFO] <TerminationManager> contains 2 active terms.\n",
            "+----------------------------+\n",
            "|  Active Termination Terms  |\n",
            "+-------+---------+----------+\n",
            "| Index | Name    | Time Out |\n",
            "+-------+---------+----------+\n",
            "|   0   | timeout |   True   |\n",
            "|   1   | tipped  |  False   |\n",
            "+-------+---------+----------+\n",
            "\n",
            "[INFO] <RewardManager> contains 2 active terms.\n",
            "+--------------------------+\n",
            "|   Active Reward Terms    |\n",
            "+-------+---------+--------+\n",
            "| Index | Name    | Weight |\n",
            "+-------+---------+--------+\n",
            "|   0   | upright |    5.0 |\n",
            "|   1   | effort  |    1.0 |\n",
            "+-------+---------+--------+\n",
            "\n",
            "[INFO] <NullCurriculumManager> (inactive)\n",
            "--------------------------------------------------------------------------------\n",
            "Resolved observation sets: \n",
            "\t policy :  ('policy',)\n",
            "\t critic :  ('critic',)\n",
            "--------------------------------------------------------------------------------\n",
            "Actor MLP: MLP(\n",
            "  (0): Linear(in_features=4, out_features=256, bias=True)\n",
            "  (1): ELU(alpha=1.0)\n",
            "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (3): ELU(alpha=1.0)\n",
            "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (5): ELU(alpha=1.0)\n",
            "  (6): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Critic MLP: MLP(\n",
            "  (0): Linear(in_features=4, out_features=256, bias=True)\n",
            "  (1): ELU(alpha=1.0)\n",
            "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (3): ELU(alpha=1.0)\n",
            "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (5): ELU(alpha=1.0)\n",
            "  (6): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ viser (listening *:8081) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
            "\n",
            "==================================================\n",
            "‚úÖ Server is running! Execute the next cell to view.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: Update this with your checkpoint path!\n",
        "checkpoint_path = \"logs/rsl_rl/cartpole/2025-12-05_17-02-08/model_950.pt\"\n",
        "\n",
        "# # Uncomment and run after updating the path:\n",
        "# # !uv run play Mjlab-Cartpole --checkpoint_file {checkpoint_path} --num_envs 4\n",
        "# !python /content/mjlab/src/mjlab/scripts/play.py Mjlab-Cartpole --checkpoint_file {checkpoint_path} --num_envs 4\n",
        "\n",
        "# print(\"‚ÑπÔ∏è Update the checkpoint_path variable above with your actual checkpoint.\")\n",
        "# print(\"   Then uncomment and run the cell.\")\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "process = subprocess.Popen(\n",
        "  [\n",
        "    \"python\",\n",
        "    \"/content/mjlab/src/mjlab/scripts/play.py\",\n",
        "    \"Mjlab-Cartpole\",\n",
        "    \"--checkpoint_file\",\n",
        "    checkpoint_path,\n",
        "    \"--num_envs\",\n",
        "    \"4\",\n",
        "  ],\n",
        "  stdout=subprocess.PIPE,\n",
        "  stderr=subprocess.STDOUT,\n",
        "  universal_newlines=True,\n",
        "  bufsize=1,\n",
        ")\n",
        "\n",
        "for line in process.stdout:\n",
        "  print(line, end=\"\")\n",
        "  sys.stdout.flush()\n",
        "\n",
        "  if \"serving\" in line.lower() or \"running on\" in line.lower() or \"8081\" in line:\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"‚úÖ Server is running! Execute the next cell to view.\")\n",
        "    print(\"=\" * 50)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "ll89QnuSuUxx",
        "outputId": "0a5e5620-dfde-46e7-fadc-36627d101db6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8081, \"/\", \"100%\", 700, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import output\n",
        "\n",
        "output.serve_kernel_port_as_iframe(\n",
        "    port=8081,\n",
        "    height=700\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN7GIEjVr9vw"
      },
      "source": [
        "### **üìπ Generate Video Recording**\n",
        "\n",
        "Record a video of the trained policy for visualization as `.viser` format."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}