{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttktjmt/mjlab/blob/main/notebooks/create_new_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO76KS1i-MwA"
      },
      "source": [
        "# **ü§ñ CartPole Tutorial with MJLab**\n",
        "\n",
        "This notebook demonstrates how to create a custom reinforcement learning task using MJLab. We'll build a CartPole environment from scratch, including:\n",
        "\n",
        "1. **Robot Definition** - Define the CartPole model in MuJoCo XML\n",
        "2. **Task Configuration** - Set up observations, actions, rewards, and terminations\n",
        "3. **Training** - Train a policy using PPO\n",
        "4. **Evaluation** - Visualize/Record the trained policy\n",
        "\n",
        "> **Note**: This tutorial is created based on the official MJLab documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ywZTgfR3C_w"
      },
      "source": [
        "## **üì¶ Setup and Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dtLMJHzy3Nee",
        "outputId": "1e4baa2e-dacc-4e80-bc7c-f4d063aab495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/content/mjlab\n",
            "‚úì Installation complete!\n"
          ]
        }
      ],
      "source": [
        "# Install uv package manager\n",
        "!pip install uv -q\n",
        "\n",
        "# Clone the mjlab repository\n",
        "!if [ ! -d \"mjlab\" ]; then git clone -q https://github.com/mujocolab/mjlab.git; fi\n",
        "%cd /content/mjlab\n",
        "\n",
        "# Install mjlab in editable mode\n",
        "!uv pip install --system -e . -q\n",
        "\n",
        "print(\"‚úì Installation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSf2943z3b0s"
      },
      "source": [
        "### **üîë WandB Setup (Optional)**\n",
        "\n",
        "Configure Weights & Biases for experiment tracking. Add your WandB API key to Colab Secrets:\n",
        "- `WANDB_API_KEY`: from [wandb.ai/authorize](https://wandb.ai/authorize)\n",
        "- `WANDB_ENTITY`: your organization name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC9ywCnm3dGg",
        "outputId": "0d34357e-577f-482d-c4a7-0f93063a69b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì WandB configured successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    os.environ['WANDB_API_KEY'] = userdata.get('WANDB_API_KEY')\n",
        "    os.environ['WANDB_ENTITY'] = userdata.get('WANDB_ENTITY')\n",
        "    print(\"‚úì WandB configured successfully!\")\n",
        "except (AttributeError, KeyError):\n",
        "    print(\"‚ö† WandB secrets not found. Training will proceed without WandB logging.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mispfmy73lmq"
      },
      "source": [
        "---\n",
        "\n",
        "## **ü§ñ Step 1: Define the Robot**\n",
        "\n",
        "We'll create a simple CartPole robot with:\n",
        "- A sliding cart (1 DOF)\n",
        "- A hinged pole (1 DOF)\n",
        "- A velocity actuator to control the cart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FvJYPWD3scd"
      },
      "source": [
        "### **üìÅ Structure Directories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP-yET-R3ofN",
        "outputId": "b9fa169e-4f5c-4b29-8368-744976503233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Directory structure created\n"
          ]
        }
      ],
      "source": [
        "# Create the cartpole robot directory structure\n",
        "!mkdir -p /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/\n",
        "!mkdir -p /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/xmls\n",
        "\n",
        "print(\"‚úì Directory structure created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRyN1Pok3u25"
      },
      "source": [
        "### **üìù Create MuJoCo XML Model**\n",
        "\n",
        "This XML defines the CartPole physics:\n",
        "- **Ground plane** for visualization\n",
        "- **Cart body** with a sliding joint (¬±2m range)\n",
        "- **Pole body** with a hinge joint (¬±90¬∞ range)\n",
        "- **Velocity actuator** for cart control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWGyFX5V3yWc",
        "outputId": "b26101e0-c03e-4095-d5a3-41ba317c07a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/xmls/cartpole.xml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/xmls/cartpole.xml\n",
        "<mujoco model=\"cartpole\">\n",
        "  <compiler angle=\"degree\" coordinate=\"local\" inertiafromgeom=\"true\"/>\n",
        "  <worldbody>\n",
        "    <geom name=\"ground\" type=\"plane\" pos=\"0 0 0\" size=\"5 5 0.1\" rgba=\"0.8 0.9 0.8 1\"/>\n",
        "    <body name=\"cart\" pos=\"0 0 0.1\">\n",
        "      <geom type=\"box\" size=\"0.2 0.1 0.1\" rgba=\"0.2 0.2 0.8 1\" mass=\"1.0\"/>\n",
        "      <joint name=\"slide\" type=\"slide\" axis=\"1 0 0\" limited=\"true\" range=\"-2 2\"/>\n",
        "      <body name=\"pole\" pos=\"0 0 0.1\">\n",
        "        <geom type=\"capsule\" size=\"0.05 0.5\" fromto=\"0 0 0 0 0 1\" rgba=\"0.8 0.2 0.2 1\" mass=\"2.0\"/>\n",
        "        <joint name=\"hinge\" type=\"hinge\" axis=\"0 1 0\" range=\"-90 90\"/>\n",
        "      </body>\n",
        "    </body>\n",
        "  </worldbody>\n",
        "  <actuator>\n",
        "    <velocity name=\"slide_velocity\" joint=\"slide\" ctrlrange=\"-20 20\" kv=\"20\"/>\n",
        "  </actuator>\n",
        "</mujoco>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpYCG9jI31dZ"
      },
      "source": [
        "### **‚öôÔ∏è Create Robot Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDhiyDTn4AVa",
        "outputId": "fc7281a7-3318-4604-ecb0-a9459f1a7026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/cartpole_constants.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/cartpole_constants.py\n",
        "# from pathlib import Path\n",
        "# import mujoco\n",
        "\n",
        "# from mjlab import MJLAB_SRC_PATH\n",
        "# from mjlab.entity import Entity, EntityCfg\n",
        "\n",
        "# CARTPOLE_XML: Path = (\n",
        "#   MJLAB_SRC_PATH / \"asset_zoo\" / \"robots\" / \"cartpole\" / \"xmls\" / \"cartpole.xml\"\n",
        "# )\n",
        "# assert CARTPOLE_XML.exists(), f\"XML not found: {CARTPOLE_XML}\"\n",
        "\n",
        "# def get_spec() -> mujoco.MjSpec:\n",
        "#   return mujoco.MjSpec.from_file(str(CARTPOLE_XML))\n",
        "\n",
        "# def get_cartpole_robot_cfg() -> EntityCfg:\n",
        "#   \"\"\"Get a fresh CartPole robot configuration instance.\"\"\"\n",
        "#   return EntityCfg(spec_fn=get_spec)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   import mujoco.viewer as viewer\n",
        "#   robot = Entity(get_cartpole_robot_cfg())\n",
        "#   viewer.launch(robot.spec.compile())\n",
        "from pathlib import Path\n",
        "import mujoco\n",
        "\n",
        "from mjlab import MJLAB_SRC_PATH\n",
        "from mjlab.entity import Entity, EntityCfg, EntityArticulationInfoCfg\n",
        "from mjlab.actuator import XmlVelocityActuatorCfg  # ‚Üê Use this import\n",
        "\n",
        "CARTPOLE_XML: Path = (\n",
        "  MJLAB_SRC_PATH / \"asset_zoo\" / \"robots\" / \"cartpole\" / \"xmls\" / \"cartpole.xml\"\n",
        ")\n",
        "assert CARTPOLE_XML.exists(), f\"XML not found: {CARTPOLE_XML}\"\n",
        "\n",
        "def get_spec() -> mujoco.MjSpec:\n",
        "  return mujoco.MjSpec.from_file(str(CARTPOLE_XML))\n",
        "\n",
        "def get_cartpole_robot_cfg() -> EntityCfg:\n",
        "  \"\"\"Get a fresh CartPole robot configuration instance.\"\"\"\n",
        "  actuators = (\n",
        "    XmlVelocityActuatorCfg(\n",
        "      joint_names_expr=(\"slide\",),  # Matches your XML actuator's target joint\n",
        "    ),\n",
        "  )\n",
        "  articulation = EntityArticulationInfoCfg(actuators=actuators)  # ‚Üê Add this\n",
        "  return EntityCfg(\n",
        "    spec_fn=get_spec,\n",
        "    articulation=articulation  # ‚Üê Add this\n",
        "  )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  import mujoco.viewer as viewer\n",
        "  robot = Entity(get_cartpole_robot_cfg())\n",
        "  viewer.launch(robot.spec.compile())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WSaDod04FwN",
        "outputId": "3fad3e9e-867c-4935-bae2-39741b939b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/__init__.py\n"
          ]
        }
      ],
      "source": [
        "# Create __init__.py for the cartpole robot package\n",
        "%%writefile /content/mjlab/src/mjlab/asset_zoo/robots/cartpole/__init__.py\n",
        "# Empty __init__.py to mark the directory as a Python package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1tiBPfp_oVP",
        "outputId": "6d6490b0-bd52-4b39-debc-ad32aa13148f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Added /content/mjlab/src to Python path\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# Append src dir to python path\n",
        "mjlab_src = '/content/mjlab/src'\n",
        "if mjlab_src not in sys.path:\n",
        "    sys.path.insert(0, mjlab_src)\n",
        "    print(f\"‚úì Added {mjlab_src} to Python path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToWF84qC4Hfg"
      },
      "source": [
        "### **‚úÖ Verify Robot Setup**\n",
        "\n",
        "Let's test that the robot can be loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tVsvqzQ4J9h",
        "outputId": "b1b060b9-a6a8-4d83-8369-38e80469be6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì CartPole robot loaded successfully!\n",
            "  ‚Ä¢ Degrees of Freedom (DOF): 2\n",
            "  ‚Ä¢ Number of Actuators: 1\n",
            "  ‚Ä¢ Bodies: 4\n",
            "  ‚Ä¢ Joints: 2\n"
          ]
        }
      ],
      "source": [
        "from mjlab.entity import Entity\n",
        "from mjlab.asset_zoo.robots.cartpole.cartpole_constants import get_cartpole_robot_cfg\n",
        "\n",
        "# Load the robot\n",
        "robot = Entity(get_cartpole_robot_cfg())\n",
        "model = robot.spec.compile()\n",
        "\n",
        "# Display robot information\n",
        "print(\"‚úì CartPole robot loaded successfully!\")\n",
        "print(f\"  ‚Ä¢ Degrees of Freedom (DOF): {model.nv}\")\n",
        "print(f\"  ‚Ä¢ Number of Actuators: {model.nu}\")\n",
        "print(f\"  ‚Ä¢ Bodies: {model.nbody}\")\n",
        "print(f\"  ‚Ä¢ Joints: {model.njnt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2_9dixlHON1"
      },
      "source": [
        "### **üìã Register the Robot**\n",
        "\n",
        "Add the CartPole robot to the asset zoo registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qDIF__lHPcb",
        "outputId": "2dae49ab-a0e9-4407-b1c5-4a69fe27019e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì CartPole robot registered in asset zoo\n"
          ]
        }
      ],
      "source": [
        "# Add CartPole import to robots __init__.py\n",
        "with open('/content/mjlab/src/mjlab/asset_zoo/robots/__init__.py', 'a') as f:\n",
        "    f.write('\\n# CartPole robot\\n')\n",
        "    f.write('from mjlab.asset_zoo.robots.cartpole.cartpole_constants import ')\n",
        "    f.write('get_cartpole_robot_cfg as get_cartpole_robot_cfg\\n')\n",
        "\n",
        "print(\"‚úì CartPole robot registered in asset zoo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lVD_L6PHWNm"
      },
      "source": [
        "---\n",
        "\n",
        "## **üéØ Step 2: Define the Task (MDP)**\n",
        "\n",
        "Now we'll define the Markov Decision Process:\n",
        "- **Observations**: pole angle, angular velocity, cart position, cart velocity\n",
        "- **Actions**: cart velocity commands\n",
        "- **Rewards**: upright reward + effort penalty\n",
        "- **Terminations**: pole tips over or timeout\n",
        "- **Events**: random pushes for robustness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQxe4TBrHb-I"
      },
      "source": [
        "### **üìÅ Create Task Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWBqdkziHc2G",
        "outputId": "cc054cb2-cdcb-44c3-f8cd-90162e837d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Task directory created\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/mjlab/src/mjlab/tasks/cartpole\n",
        "\n",
        "print(\"‚úì Task directory created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJfjPpm0Hhj1"
      },
      "source": [
        "### **üìù Create Environment Configuration**\n",
        "\n",
        "This file contains all MDP components:\n",
        "1. **Scene Config**: 64 parallel environments\n",
        "2. **Actions**: Joint position control with 20.0 scale\n",
        "3. **Observations**: Normalized state variables\n",
        "4. **Rewards**: Upright reward (5.0) + effort penalty (-0.01)\n",
        "5. **Events**: Joint resets + random pushes\n",
        "6. **Terminations**: Pole tipped (>30¬∞) or timeout (10s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "javx9XDIHkFI",
        "outputId": "c89f66ac-0ccd-403a-bb32-c3d37f1b9369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/mjlab/src/mjlab/tasks/cartpole/cartpole_env_cfg.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/tasks/cartpole/cartpole_env_cfg.py\n",
        "\"\"\"CartPole task environment configuration.\"\"\"\n",
        "\n",
        "import math\n",
        "import torch\n",
        "\n",
        "from mjlab.envs import ManagerBasedRlEnvCfg\n",
        "from mjlab.envs.mdp.actions import JointVelocityActionCfg, JointPositionActionCfg\n",
        "from mjlab.managers.manager_term_config import (\n",
        "  ObservationGroupCfg,\n",
        "  ObservationTermCfg,\n",
        "  RewardTermCfg,\n",
        "  TerminationTermCfg,\n",
        "  EventTermCfg,\n",
        ")\n",
        "from mjlab.managers.scene_entity_config import SceneEntityCfg\n",
        "from mjlab.scene import SceneCfg\n",
        "from mjlab.sim import MujocoCfg, SimulationCfg\n",
        "from mjlab.viewer import ViewerConfig\n",
        "from mjlab.asset_zoo.robots.cartpole.cartpole_constants import get_cartpole_robot_cfg\n",
        "from mjlab.rl import RslRlOnPolicyRunnerCfg\n",
        "from mjlab.envs import mdp\n",
        "\n",
        "# ==============================================================================\n",
        "# Scene Configuration\n",
        "# ==============================================================================\n",
        "\n",
        "SCENE_CFG = SceneCfg(\n",
        "  num_envs=64,  # Number of parallel environments\n",
        "  extent=1.0,   # Spacing between environments\n",
        "  entities={\"robot\": get_cartpole_robot_cfg()},\n",
        ")\n",
        "\n",
        "VIEWER_CONFIG = ViewerConfig(\n",
        "  origin_type=ViewerConfig.OriginType.ASSET_BODY,\n",
        "  asset_name=\"robot\",\n",
        "  body_name=\"pole\",\n",
        "  distance=3.0,\n",
        "  elevation=10.0,\n",
        "  azimuth=90.0,\n",
        ")\n",
        "\n",
        "SIM_CFG = SimulationCfg(\n",
        "  mujoco=MujocoCfg(\n",
        "    timestep=0.02,  # 50 Hz control\n",
        "    iterations=1,\n",
        "  ),\n",
        ")\n",
        "\n",
        "# ==============================================================================\n",
        "# Actions\n",
        "# ==============================================================================\n",
        "\n",
        "def create_cartpole_actions() -> dict[str, JointVelocityActionCfg]:\n",
        "  \"\"\"Create CartPole actions.\"\"\"\n",
        "  return {\n",
        "    \"slide\": JointVelocityActionCfg(\n",
        "      asset_name=\"robot\",\n",
        "      actuator_names=(\".*\",),\n",
        "      scale=20.0,\n",
        "      use_default_offset=False,\n",
        "    ),\n",
        "  }\n",
        "# def create_cartpole_actions() -> dict[str, JointPositionActionCfg]:\n",
        "#   \"\"\"Create CartPole actions.\"\"\"\n",
        "#   return {\n",
        "#     \"joint_pos\": JointPositionActionCfg(\n",
        "#       asset_name=\"robot\",\n",
        "#       actuator_names=(\".*\",),\n",
        "#       scale=20.0,\n",
        "#       use_default_offset=False,\n",
        "#     ),\n",
        "#   }\n",
        "\n",
        "# ==============================================================================\n",
        "# Observations\n",
        "# ==============================================================================\n",
        "\n",
        "def create_cartpole_observations() -> dict[str, ObservationGroupCfg]:\n",
        "  \"\"\"Create CartPole observations.\"\"\"\n",
        "  policy_terms = {\n",
        "    \"angle\": ObservationTermCfg(\n",
        "      func=lambda env: env.sim.data.qpos[:, 1:2] / math.pi\n",
        "    ),\n",
        "    \"ang_vel\": ObservationTermCfg(\n",
        "      func=lambda env: env.sim.data.qvel[:, 1:2] / 5.0\n",
        "    ),\n",
        "    \"cart_pos\": ObservationTermCfg(\n",
        "      func=lambda env: env.sim.data.qpos[:, 0:1] / 2.0\n",
        "    ),\n",
        "    \"cart_vel\": ObservationTermCfg(\n",
        "      func=lambda env: env.sim.data.qvel[:, 0:1] / 20.0\n",
        "    ),\n",
        "  }\n",
        "\n",
        "  return {\n",
        "    \"policy\": ObservationGroupCfg(\n",
        "      terms=policy_terms,\n",
        "      concatenate_terms=True,\n",
        "    ),\n",
        "    \"critic\": ObservationGroupCfg(\n",
        "      terms=policy_terms,  # Critic uses same observations\n",
        "      concatenate_terms=True,\n",
        "    ),\n",
        "  }\n",
        "\n",
        "# ==============================================================================\n",
        "# Rewards\n",
        "# ==============================================================================\n",
        "\n",
        "def compute_upright_reward(env):\n",
        "  \"\"\"Reward for keeping pole upright (cosine of angle).\"\"\"\n",
        "  return env.sim.data.qpos[:, 1].cos()\n",
        "\n",
        "def compute_effort_penalty(env):\n",
        "  \"\"\"Penalty for control effort.\"\"\"\n",
        "  return -0.01 * (env.sim.data.ctrl[:, 0] ** 2)\n",
        "\n",
        "def create_cartpole_rewards() -> dict[str, RewardTermCfg]:\n",
        "  \"\"\"Create CartPole rewards.\"\"\"\n",
        "  return {\n",
        "    \"upright\": RewardTermCfg(func=compute_upright_reward, weight=5.0),\n",
        "    \"effort\": RewardTermCfg(func=compute_effort_penalty, weight=1.0),\n",
        "  }\n",
        "\n",
        "# ==============================================================================\n",
        "# Events\n",
        "# ==============================================================================\n",
        "\n",
        "def random_push_cart(env, env_ids, force_range=(-5, 5)):\n",
        "  \"\"\"Apply random force to cart for robustness training.\"\"\"\n",
        "  n = len(env_ids)\n",
        "  random_forces = (\n",
        "    torch.rand(n, device=env.device) *\n",
        "    (force_range[1] - force_range[0]) +\n",
        "    force_range[0]\n",
        "  )\n",
        "  env.sim.data.qfrc_applied[env_ids, 0] = random_forces\n",
        "\n",
        "def create_cartpole_events() -> dict[str, EventTermCfg]:\n",
        "  \"\"\"Create CartPole events.\"\"\"\n",
        "  return {\n",
        "    \"reset_robot_joints\": EventTermCfg(\n",
        "      func=mdp.reset_joints_by_offset,\n",
        "      mode=\"reset\",\n",
        "      params={\n",
        "        \"asset_cfg\": SceneEntityCfg(\"robot\"),\n",
        "        \"position_range\": (-0.1, 0.1),\n",
        "        \"velocity_range\": (-0.1, 0.1),\n",
        "      },\n",
        "    ),\n",
        "    \"random_push\": EventTermCfg(\n",
        "      func=random_push_cart,\n",
        "      mode=\"interval\",\n",
        "      interval_range_s=(1.0, 2.0),\n",
        "      params={\"force_range\": (-20.0, 20.0)},\n",
        "    ),\n",
        "  }\n",
        "\n",
        "# ==============================================================================\n",
        "# Terminations\n",
        "# ==============================================================================\n",
        "\n",
        "def check_pole_tipped(env):\n",
        "  \"\"\"Check if pole has tipped beyond 30 degrees.\"\"\"\n",
        "  return env.sim.data.qpos[:, 1].abs() > math.radians(30)\n",
        "\n",
        "def create_cartpole_terminations() -> dict[str, TerminationTermCfg]:\n",
        "  \"\"\"Create CartPole terminations.\"\"\"\n",
        "  return {\n",
        "    \"timeout\": TerminationTermCfg(func=mdp.time_out, time_out=True),\n",
        "    \"tipped\": TerminationTermCfg(func=check_pole_tipped, time_out=False),\n",
        "  }\n",
        "\n",
        "# ==============================================================================\n",
        "# Environment Configuration\n",
        "# ==============================================================================\n",
        "\n",
        "def create_cartpole_env_cfg() -> ManagerBasedRlEnvCfg:\n",
        "  \"\"\"Create CartPole environment configuration.\"\"\"\n",
        "  return ManagerBasedRlEnvCfg(\n",
        "    scene=SCENE_CFG,\n",
        "    observations=create_cartpole_observations(),\n",
        "    actions=create_cartpole_actions(),\n",
        "    rewards=create_cartpole_rewards(),\n",
        "    events=create_cartpole_events(),\n",
        "    terminations=create_cartpole_terminations(),\n",
        "    sim=SIM_CFG,\n",
        "    viewer=VIEWER_CONFIG,\n",
        "    decimation=1,           # No action repeat\n",
        "    episode_length_s=10.0,  # 10 second episodes\n",
        "  )\n",
        "\n",
        "# Module-level constant for gymnasium registration\n",
        "CARTPOLE_ENV_CFG = create_cartpole_env_cfg()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Reload the catpole module\n",
        "# import importlib\n",
        "# import mjlab.asset_zoo.robots.cartpole.cartpole_constants\n",
        "# importlib.reload(mjlab.asset_zoo.robots.cartpole.cartpole_constants)\n",
        "\n",
        "# # Run diagnostic script\n",
        "# from mjlab.entity import Entity\n",
        "# from mjlab.asset_zoo.robots.cartpole.cartpole_constants import get_cartpole_robot_cfg\n",
        "\n",
        "# robot_cfg = get_cartpole_robot_cfg()\n",
        "# print(f\"‚úì Robot Config has articulation: {robot_cfg.articulation is not None}\")\n",
        "\n",
        "# if robot_cfg.articulation:\n",
        "#     print(f\"‚úì Number of actuator configs: {len(robot_cfg.articulation.actuators)}\")\n",
        "#     for act_cfg in robot_cfg.articulation.actuators:\n",
        "#         print(f\"  ‚Ä¢ {type(act_cfg).__name__}\")\n",
        "\n",
        "# robot = Entity(robot_cfg)\n",
        "# print(f\"\\n‚úì Entity is_actuated: {robot.is_actuated}\")\n",
        "# print(f\"‚úì Number of actuators: {robot.num_actuators}\")\n",
        "# print(f\"‚úì Internal _actuators length: {len(robot._actuators)}\")\n",
        "\n",
        "# if len(robot._actuators) > 0:\n",
        "#     print(f\"‚úì Actuator type: {type(robot._actuators[0]).__name__}\")\n",
        "#     print(f\"‚úì Controlled joints: {robot._actuators[0].joint_names}\")"
      ],
      "metadata": {
        "id": "h7H3U64Y2YeV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc8-AHGcHt78"
      },
      "source": [
        "### **üìã Register the Task Environment**\n",
        "\n",
        "Register the CartPole task with Gymnasium."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZX_b_vQTBLU",
        "outputId": "3f26215d-ec52-4419-b2e5-90ea2d011390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16\n",
            "drwxr-xr-x 2 root root 4096 Dec  5 10:23 .\n",
            "drwxr-xr-x 6 root root 4096 Dec  5 10:23 ..\n",
            "-rw-r--r-- 1 root root 6079 Dec  5 10:23 cartpole_env_cfg.py\n"
          ]
        }
      ],
      "source": [
        "!ls -la /content/mjlab/src/mjlab/tasks/cartpole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BEPKiedIlRh",
        "outputId": "9fe2a2a6-833f-4f6c-f1f2-9ade6eeb52dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Warp 1.10.1 initialized:\n",
            "   CUDA driver not found or failed to initialize\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.10.1\n",
            "\n",
            "+--------------------------------+\n",
            "|        Base Environment        |\n",
            "+------------------------+-------+\n",
            "| Property               | Value |\n",
            "+------------------------+-------+\n",
            "| Number of environments | 64    |\n",
            "| Environment device     | cpu   |\n",
            "| Environment seed       | None  |\n",
            "| Physics step-size      | 0.02  |\n",
            "| Environment step-size  | 0.02  |\n",
            "+------------------------+-------+\n",
            "\n",
            "[INFO] <EventManager> contains 2 active terms.\n",
            "+-------------------------------------+\n",
            "| Active Event Terms in Mode: 'reset' |\n",
            "+--------+----------------------------+\n",
            "| Index  | Name                       |\n",
            "+--------+----------------------------+\n",
            "|   0    | reset_robot_joints         |\n",
            "+--------+----------------------------+\n",
            "+-----------------------------------------------+\n",
            "|     Active Event Terms in Mode: 'interval'    |\n",
            "+-------+-------------+-------------------------+\n",
            "| Index | Name        | Interval time range (s) |\n",
            "+-------+-------------+-------------------------+\n",
            "|   0   | random_push |        (1.0, 2.0)       |\n",
            "+-------+-------------+-------------------------+\n",
            "\n",
            "[INFO] <NullCommandManager> (inactive)\n",
            "[INFO] <ActionManager> contains 1 active terms.\n",
            "+--------------------------------+\n",
            "| Active Action Terms (shape: 1) |\n",
            "+--------+--------+--------------+\n",
            "| Index  | Name   |    Dimension |\n",
            "+--------+--------+--------------+\n",
            "|   0    | slide  |            1 |\n",
            "+--------+--------+--------------+\n",
            "\n",
            "[INFO] <ObservationManager> contains 2 groups.\n",
            "+-----------------------------------------------------------+\n",
            "| Active Observation Terms in Group: 'policy' (shape: (4,)) |\n",
            "+----------------+------------------------+-----------------+\n",
            "|     Index      | Name                   |      Shape      |\n",
            "+----------------+------------------------+-----------------+\n",
            "|       0        | angle                  |       (1,)      |\n",
            "|       1        | ang_vel                |       (1,)      |\n",
            "|       2        | cart_pos               |       (1,)      |\n",
            "|       3        | cart_vel               |       (1,)      |\n",
            "+----------------+------------------------+-----------------+\n",
            "+-----------------------------------------------------------+\n",
            "| Active Observation Terms in Group: 'critic' (shape: (4,)) |\n",
            "+----------------+------------------------+-----------------+\n",
            "|     Index      | Name                   |      Shape      |\n",
            "+----------------+------------------------+-----------------+\n",
            "|       0        | angle                  |       (1,)      |\n",
            "|       1        | ang_vel                |       (1,)      |\n",
            "|       2        | cart_pos               |       (1,)      |\n",
            "|       3        | cart_vel               |       (1,)      |\n",
            "+----------------+------------------------+-----------------+\n",
            "\n",
            "[INFO] <TerminationManager> contains 2 active terms.\n",
            "+----------------------------+\n",
            "|  Active Termination Terms  |\n",
            "+-------+---------+----------+\n",
            "| Index | Name    | Time Out |\n",
            "+-------+---------+----------+\n",
            "|   0   | timeout |   True   |\n",
            "|   1   | tipped  |  False   |\n",
            "+-------+---------+----------+\n",
            "\n",
            "[INFO] <RewardManager> contains 2 active terms.\n",
            "+--------------------------+\n",
            "|   Active Reward Terms    |\n",
            "+-------+---------+--------+\n",
            "| Index | Name    | Weight |\n",
            "+-------+---------+--------+\n",
            "|   0   | upright |    5.0 |\n",
            "|   1   | effort  |    1.0 |\n",
            "+-------+---------+--------+\n",
            "\n",
            "[INFO] <NullCurriculumManager> (inactive)\n",
            "‚úì CartPole environment created successfully!\n",
            "\n",
            "Environment Details:\n",
            "  ‚Ä¢ Number of environments: 64\n",
            "  ‚Ä¢ Observation space: Dict(shape=(64,), dtype='float32', spaces={'policy': Box(shape=(64, 4), dtype='float32', low=-inf, high=inf), 'critic': Box(shape=(64, 4), dtype='float32', low=-inf, high=inf)})\n",
            "  ‚Ä¢ Action space: Box(shape=(64, 1), dtype='float32', low=-inf, high=inf)\n",
            "Module mujoco_warp._src.smooth bf695c4 load on device 'cpu' took 8744.43 ms  (compiled)\n",
            "Module mujoco_warp._src.collision_driver d899a08 load on device 'cpu' took 2527.43 ms  (compiled)\n",
            "Module _nxn_broadphase__locals__kernel_1799b5b8 321d855 load on device 'cpu' took 4054.61 ms  (compiled)\n",
            "Module mujoco_warp._src.collision_primitive._create_narrowphase_kernel af9b8fc load on device 'cpu' took 3720.89 ms  (compiled)\n",
            "Module mujoco_warp._src.constraint d752241 load on device 'cpu' took 4929.01 ms  (compiled)\n",
            "Module _actuator_velocity__locals__actuator_velocity_7933d235 30a9676 load on device 'cpu' took 3653.43 ms  (compiled)\n",
            "Module mujoco_warp._src.passive 688bc90 load on device 'cpu' took 4053.42 ms  (compiled)\n",
            "Module mujoco_warp._src.forward ad39c93 load on device 'cpu' took 3333.85 ms  (compiled)\n",
            "Module mujoco_warp._src.support f372de6 load on device 'cpu' took 3225.97 ms  (compiled)\n",
            "Module _tile_cholesky_factorize_solve__locals__cholesky_factorize_solve_43a10bd2 15099e1 load on device 'cpu' took 3087.86 ms  (compiled)\n",
            "Module mujoco_warp._src.solver 5a47c9c load on device 'cpu' took 4349.31 ms  (compiled)\n",
            "Module mul_m_dense__locals___mul_m_dense_34acc5d2 9a79ecc load on device 'cpu' took 2612.45 ms  (compiled)\n",
            "Module update_constraint_gauss_cost__locals__kernel_fd0aa713 9cfe5d8 load on device 'cpu' took 3405.09 ms  (compiled)\n",
            "Module update_gradient_JTDAJ_dense_tiled__locals__kernel_fcb58f0e cd574e3 load on device 'cpu' took 3057.21 ms  (compiled)\n",
            "Module update_gradient_cholesky__locals__kernel_b2b7bfef 94d9e19 load on device 'cpu' took 2641.90 ms  (compiled)\n",
            "Module linesearch_jv_fused__locals__kernel_90eb52be 0e7e071 load on device 'cpu' took 2497.29 ms  (compiled)\n",
            "\n",
            "  ‚Ä¢ Observation shape: torch.Size([64, 4])\n",
            "  ‚Ä¢ Sample observation: tensor([ 0.0141, -0.0055, -0.0364,  0.0035])\n",
            "‚úó Error: 'Box' object has no attribute 'sample'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3697679794.py\", line 24, in <cell line: 0>\n",
            "    action = env.action_space.sample()\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'Box' object has no attribute 'sample'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from mjlab.envs import ManagerBasedRlEnv\n",
        "from mjlab.tasks.cartpole.cartpole_env_cfg import CARTPOLE_ENV_CFG\n",
        "\n",
        "# Create environment directly\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\\n\")\n",
        "\n",
        "try:\n",
        "    env = ManagerBasedRlEnv(cfg=CARTPOLE_ENV_CFG, device=device)\n",
        "\n",
        "    print(\"‚úì CartPole environment created successfully!\\n\")\n",
        "    print(\"Environment Details:\")\n",
        "    print(f\"  ‚Ä¢ Number of environments: {env.num_envs}\")\n",
        "    print(f\"  ‚Ä¢ Observation space: {env.observation_space}\")\n",
        "    print(f\"  ‚Ä¢ Action space: {env.action_space}\")\n",
        "\n",
        "    # Test a reset\n",
        "    obs, info = env.reset()\n",
        "    print(f\"\\n  ‚Ä¢ Observation shape: {obs['policy'].shape}\")\n",
        "    print(f\"  ‚Ä¢ Sample observation: {obs['policy'][0]}\")\n",
        "\n",
        "    # Test a step\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    print(f\"\\n  ‚Ä¢ Reward shape: {reward.shape}\")\n",
        "    print(f\"  ‚Ä¢ Sample reward: {reward[0].item():.4f}\")\n",
        "\n",
        "    env.close()\n",
        "    print(\"\\n‚úì Environment test completed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚úó Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YitUGUBRHxD4",
        "outputId": "77fe045b-8aa0-4405-83df-2eb6cfa0cae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/mjlab/src/mjlab/tasks/cartpole/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/mjlab/src/mjlab/tasks/cartpole/__init__.py\n",
        "import gymnasium as gym\n",
        "\n",
        "from .cartpole_env_cfg import CARTPOLE_ENV_CFG\n",
        "\n",
        "gym.register(\n",
        "  id=\"Mjlab-Cartpole\",\n",
        "  entry_point=\"mjlab.envs:ManagerBasedRlEnv\",\n",
        "  disable_env_checker=True,\n",
        "  kwargs={\n",
        "    \"env_cfg_entry_point\": CARTPOLE_ENV_CFG,\n",
        "    \"rl_cfg_entry_point\": f\"{__name__}.cartpole_env_cfg:RslRlOnPolicyRunnerCfg\",\n",
        "  },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tV5SxDFH3MT",
        "outputId": "6a98b3ba-3a5e-4e2b-a79f-7ee2da54bb47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì CartPole task registered\n"
          ]
        }
      ],
      "source": [
        "# Add CartPole task import to tasks __init__.py\n",
        "with open('/content/mjlab/src/mjlab/tasks/__init__.py', 'a') as f:\n",
        "    f.write('\\n# CartPole task\\n')\n",
        "    f.write('from mjlab.tasks import cartpole\\n')\n",
        "\n",
        "print(\"‚úì CartPole task registered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyJpGMP4H6rN"
      },
      "source": [
        "### **‚úÖ Verify Environment Registration**\n",
        "\n",
        "Let's test that the environment is properly registered and can be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7q0NH0rLm4_",
        "outputId": "a4f9d001-2b4a-441b-a678-d3555cb1805b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úó Environment not found in registry\n"
          ]
        }
      ],
      "source": [
        "from mjlab.tasks import cartpole\n",
        "\n",
        "# Check if environment is registered\n",
        "env_specs = gym.envs.registry\n",
        "if \"Mjlab-Cartpole\" in env_specs:\n",
        "    print(\"‚úì Mjlab-Cartpole environment successfully registered!\\n\")\n",
        "\n",
        "    # Create a test environment\n",
        "    env = gym.make(\"Mjlab-Cartpole\", headless=True)\n",
        "\n",
        "    print(\"Environment Details:\")\n",
        "    print(f\"  ‚Ä¢ Observation space: {env.observation_space}\")\n",
        "    print(f\"  ‚Ä¢ Action space: {env.action_space}\")\n",
        "    print(f\"  ‚Ä¢ Number of environments: {env.unwrapped.num_envs}\")\n",
        "\n",
        "    # Test a step\n",
        "    obs, info = env.reset()\n",
        "    print(f\"\\n  ‚Ä¢ Observation shape: {obs['policy'].shape}\")\n",
        "    print(f\"  ‚Ä¢ Sample observation: {obs['policy'][0]}\")\n",
        "\n",
        "    env.close()\n",
        "    print(\"\\n‚úì Environment test completed successfully!\")\n",
        "else:\n",
        "    print(\"‚úó Environment not found in registry\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **üöÄ Step 3: Train the Agent**\n",
        "\n",
        "Now let's train a PPO policy to balance the CartPole!\n",
        "\n",
        "**Training Configuration:**\n",
        "- Algorithm: PPO (Proximal Policy Optimization)\n",
        "- Parallel Environments: 64\n",
        "- Episode Length: 10 seconds (500 steps @ 50Hz)\n",
        "- Total Steps: ~5-10 million (adjust as needed)\n",
        "\n",
        "> **Note**: Training in Colab runs in headless mode (no visualization). Progress will be logged to the console and optionally to WandB."
      ],
      "metadata": {
        "id": "K7wqLZR1rnGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the CartPole task\n",
        "# This will take several minutes depending on your training configuration\n",
        "# !uv run train Mjlab-Cartpole --system --headless --total_steps 3000000\n",
        "!python /content/mjlab/src/mjlab/scripts/train.py Mjlab-Cartpole --headless --total_steps 3000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hht_hF4trqP2",
        "outputId": "c51996ff-0098-423b-a8a8-091bbf86fc94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m‚ï≠\u001b[0m\u001b[31m‚îÄ\u001b[0m\u001b[m\u001b[0m\u001b[m \u001b[0m\u001b[31;1mInvalid\u001b[0m\u001b[31;1m choice\u001b[0m\u001b[m\u001b[0m\u001b[m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[minvalid\u001b[0m\u001b[m choice\u001b[0m\u001b[m 'Mjlab-Cartpole'\u001b[0m\u001b[m for\u001b[0m\u001b[m argument\u001b[0m\u001b[m '{Mjlab-Lift-Cube-Yam,         \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[mMjlab-Tracking-Flat-Unitree-G1,                                             \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[mMjlab-Tracking-Flat-Unitree-G1-No-State-Estimation,                         \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[mMjlab-Velocity-Flat-Unitree-G1,\u001b[0m\u001b[mMjlab-Velocity-Flat-Unitree-Go1,             \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[mMjlab-Velocity-Flat-Unitree-Go1-ActuatorNet,\u001b[0m\u001b[mMjlab-Velocity-Rough-Unitree-G1,\u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[mMjlab-Velocity-Rough-Unitree-Go1}'.\u001b[0m\u001b[m Expected\u001b[0m\u001b[m one\u001b[0m\u001b[m of\u001b[0m\u001b[m ('Mjlab-Lift-Cube-Yam', \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[m'Mjlab-Tracking-Flat-Unitree-G1',                                           \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[m'Mjlab-Tracking-Flat-Unitree-G1-No-State-Estimation',                       \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[m'Mjlab-Velocity-Flat-Unitree-G1',\u001b[0m\u001b[m 'Mjlab-Velocity-Flat-Unitree-Go1',        \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[m'Mjlab-Velocity-Flat-Unitree-Go1-ActuatorNet',                              \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚îÇ\u001b[0m \u001b[m'Mjlab-Velocity-Rough-Unitree-G1',\u001b[0m\u001b[m 'Mjlab-Velocity-Rough-Unitree-Go1').     \u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
            "\u001b[31m‚ï∞\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚ïØ\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìä Monitor Training Progress**\n",
        "\n",
        "If WandB is configured, you can monitor training in real-time."
      ],
      "metadata": {
        "id": "NYVp0-I1rqzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "if 'WANDB_API_KEY' in os.environ:\n",
        "    entity = os.environ.get('WANDB_ENTITY', 'your-entity')\n",
        "    print(f\"üìä WandB Dashboard: https://wandb.ai/{entity}\")\n",
        "    print(\"\\nTraining metrics to watch:\")\n",
        "    print(\"  ‚Ä¢ Episode Reward Mean - Should increase over time\")\n",
        "    print(\"  ‚Ä¢ Episode Length Mean - Should approach max episode length\")\n",
        "    print(\"  ‚Ä¢ Policy Loss - Should stabilize\")\n",
        "    print(\"  ‚Ä¢ Value Loss - Should decrease\")\n",
        "else:\n",
        "    print(\"‚ö† WandB not configured\")\n",
        "    print(\"Training logs are saved locally in: logs/rsl_rl/cartpole/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiaWCSz_rv7Y",
        "outputId": "f43cde6a-d070-4e19-8080-eba867999712"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä WandB Dashboard: https://wandb.ai/ttktjmt-org-org\n",
            "\n",
            "Training metrics to watch:\n",
            "  ‚Ä¢ Episode Reward Mean - Should increase over time\n",
            "  ‚Ä¢ Episode Length Mean - Should approach max episode length\n",
            "  ‚Ä¢ Policy Loss - Should stabilize\n",
            "  ‚Ä¢ Value Loss - Should decrease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìÅ Locate Training Checkpoints**\n",
        "\n",
        "After training, checkpoints are saved locally."
      ],
      "metadata": {
        "id": "xCaqPznGrx8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Find the most recent training run\n",
        "log_dir = Path(\"logs/rsl_rl/cartpole\")\n",
        "if log_dir.exists():\n",
        "    runs = sorted(log_dir.glob(\"*\"), key=os.path.getmtime, reverse=True)\n",
        "    if runs:\n",
        "        latest_run = runs[0]\n",
        "        print(f\"‚úì Latest training run: {latest_run.name}\\n\")\n",
        "\n",
        "        # List checkpoints\n",
        "        checkpoints = sorted(latest_run.glob(\"model_*.pt\"))\n",
        "        if checkpoints:\n",
        "            print(f\"Found {len(checkpoints)} checkpoints:\")\n",
        "            for ckpt in checkpoints[-5:]:  # Show last 5\n",
        "                size_mb = ckpt.stat().st_size / (1024 * 1024)\n",
        "                print(f\"  ‚Ä¢ {ckpt.name} ({size_mb:.2f} MB)\")\n",
        "\n",
        "            # Store the best checkpoint path\n",
        "            best_checkpoint = str(checkpoints[-1])\n",
        "            print(f\"\\nüíæ Best checkpoint: {best_checkpoint}\")\n",
        "        else:\n",
        "            print(\"‚ö† No checkpoints found yet\")\n",
        "    else:\n",
        "        print(\"‚ö† No training runs found\")\n",
        "else:\n",
        "    print(\"‚ö† Log directory not found. Have you run training yet?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPnmHYu8r0uY",
        "outputId": "237708bf-4b8b-48ad-b3f7-66e314ce382e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Log directory not found. Have you run training yet?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **üéÆ Step 4: Evaluate the Trained Policy**\n",
        "\n",
        "Let's test the trained policy! Since we're in Colab (headless), we can:\n",
        "1. Run the policy and print statistics\n",
        "2. Generate a video recording (optional)"
      ],
      "metadata": {
        "id": "eWFS9Pw7r2uH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üéØ Run Policy Inference**\n",
        "\n",
        "Replace `<checkpoint_path>` with your actual checkpoint path from above."
      ],
      "metadata": {
        "id": "78PgHtpfr5sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: Update this with your checkpoint path!\n",
        "checkpoint_path = \"logs/rsl_rl/cartpole/YYYY-MM-DD_HH-MM-SS/model_XXXX.pt\"\n",
        "\n",
        "# Uncomment and run after updating the path:\n",
        "!uv run play Mjlab-Cartpole --system --checkpoint_file {checkpoint_path} --headless --num_envs 4\n",
        "\n",
        "print(\"‚ÑπÔ∏è Update the checkpoint_path variable above with your actual checkpoint.\")\n",
        "print(\"   Then uncomment and run the cell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9tGiFyBr2bW",
        "outputId": "c2045a91-4447-4586-8dbb-b0af9a39e70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPython \u001b[36m3.13.10\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m154 packages\u001b[0m \u001b[2min 2.30s\u001b[0m\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"/content/mjlab/.venv/bin/play\"\u001b[0m, line \u001b[35m4\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    from mjlab.scripts.play import main\n",
            "  File \u001b[35m\"/content/mjlab/src/mjlab/scripts/play.py\"\u001b[0m, line \u001b[35m15\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    from mjlab.tasks.registry import list_tasks, load_env_cfg, load_rl_cfg, load_runner_cls\n",
            "  File \u001b[35m\"/content/mjlab/src/mjlab/tasks/__init__.py\"\u001b[0m, line \u001b[35m5\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    \u001b[31mimport_packages\u001b[0m\u001b[1;31m(__name__, _BLACKLIST_PKGS)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/content/mjlab/src/mjlab/utils/lab_api/tasks/importer.py\"\u001b[0m, line \u001b[35m40\u001b[0m, in \u001b[35mimport_packages\u001b[0m\n",
            "    for _ in \u001b[31m_walk_packages\u001b[0m\u001b[1;31m(\u001b[0m\n",
            "             \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
            "      \u001b[1;31mpackage.__path__, package.__name__ + \".\", blacklist_pkgs=blacklist_pkgs\u001b[0m\n",
            "      \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "    \u001b[1;31m)\u001b[0m:\n",
            "    \u001b[1;31m^\u001b[0m\n",
            "  File \u001b[35m\"/content/mjlab/src/mjlab/utils/lab_api/tasks/importer.py\"\u001b[0m, line \u001b[35m77\u001b[0m, in \u001b[35m_walk_packages\u001b[0m\n",
            "    \u001b[31m__import__\u001b[0m\u001b[1;31m(info.name)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/content/mjlab/src/mjlab/tasks/cartpole/__init__.py\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    import gymnasium as gym\n",
            "\u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'gymnasium'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "\n",
        "output.serve_kernel_port_as_iframe(\n",
        "    port=8081,\n",
        "    height=700\n",
        ")"
      ],
      "metadata": {
        "id": "ll89QnuSuUxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìπ Generate Video Recording**\n",
        "\n",
        "Record a video of the trained policy for visualization as `.viser` format."
      ],
      "metadata": {
        "id": "ZN7GIEjVr9vw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPxSPD8fZsoTFADE04dw0ia",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}